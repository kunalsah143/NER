{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "seq2seq_attention.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sv9uZDqBs15A",
        "outputId": "427d8733-883e-4737-d7f2-f277e9dbf945"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# !pip install contractions\n",
        "# import contractions\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "from absl import logging\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "import re    #module for regular expression operations\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "zSI2ByJNs1pU",
        "outputId": "cef2a295-d194-4d5b-dafe-13438126a6fc"
      },
      "source": [
        "Data = pd.read_csv('TrainData.csv')\n",
        "Data['Sentences'] = Data['Sentences'].apply(lambda x: '<sos> '+x+' <eos>')\n",
        "Data['Tags'] = Data['Tags'].apply(lambda x: '<tsos> '+x+' <teos>')\n",
        "Data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentences</th>\n",
              "      <th>Tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;sos&gt; what movies star bruce willis &lt;eos&gt;</td>\n",
              "      <td>&lt;tsos&gt; O O O B-ACTOR I-ACTOR &lt;teos&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;sos&gt; show me films with drew barrymore from t...</td>\n",
              "      <td>&lt;tsos&gt; O O O O B-ACTOR I-ACTOR O O B-YEAR &lt;teos&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;sos&gt; what movies starred both al pacino and r...</td>\n",
              "      <td>&lt;tsos&gt; O O O O B-ACTOR I-ACTOR O B-ACTOR I-ACT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;sos&gt; find me all of the movies that starred h...</td>\n",
              "      <td>&lt;tsos&gt; O O O O O O O O B-ACTOR I-ACTOR O B-ACT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;sos&gt; find me a movie with a quote about baseb...</td>\n",
              "      <td>&lt;tsos&gt; O O O O O O O O O O O &lt;teos&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Sentences                                               Tags\n",
              "0          <sos> what movies star bruce willis <eos>                <tsos> O O O B-ACTOR I-ACTOR <teos>\n",
              "1  <sos> show me films with drew barrymore from t...   <tsos> O O O O B-ACTOR I-ACTOR O O B-YEAR <teos>\n",
              "2  <sos> what movies starred both al pacino and r...  <tsos> O O O O B-ACTOR I-ACTOR O B-ACTOR I-ACT...\n",
              "3  <sos> find me all of the movies that starred h...  <tsos> O O O O O O O O B-ACTOR I-ACTOR O B-ACT...\n",
              "4  <sos> find me a movie with a quote about baseb...                <tsos> O O O O O O O O O O O <teos>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "9r_42TX9s1Uj",
        "outputId": "42f72904-295c-403d-ff05-768e2f0c204a"
      },
      "source": [
        "val_split = 0.2\n",
        "N = Data.values.shape[0]\n",
        "train_data = Data.values[int(N*val_split):,0:2]\n",
        "test_data = pd.read_csv(\"./TestData.csv\")\n",
        "test_data['Sentences'] = test_data['Sentences'].apply(lambda x: '<sos> '+x+' <eos>')\n",
        "test_data['Tags'] = test_data['Tags'].apply(lambda x: '<tsos> '+x+' <teos>')\n",
        "test_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentences</th>\n",
              "      <th>Tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;sos&gt; are there any good romantic comedies out...</td>\n",
              "      <td>&lt;tsos&gt; O O O O B-GENRE I-GENRE O B-YEAR I-YEAR...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;sos&gt; show me a movie about cars that talk &lt;eos&gt;</td>\n",
              "      <td>&lt;tsos&gt; O O O O O B-PLOT I-PLOT I-PLOT &lt;teos&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;sos&gt; list the five star rated movies starring...</td>\n",
              "      <td>&lt;tsos&gt; O O B-RATINGS_AVERAGE I-RATINGS_AVERAGE...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;sos&gt; what science fiction films have come out...</td>\n",
              "      <td>&lt;tsos&gt; O B-GENRE I-GENRE O O O O B-YEAR &lt;teos&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;sos&gt; did the same director make all of the ha...</td>\n",
              "      <td>&lt;tsos&gt; O O O O O O O O B-TITLE I-TITLE O &lt;teos&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Sentences                                               Tags\n",
              "0  <sos> are there any good romantic comedies out...  <tsos> O O O O B-GENRE I-GENRE O B-YEAR I-YEAR...\n",
              "1   <sos> show me a movie about cars that talk <eos>       <tsos> O O O O O B-PLOT I-PLOT I-PLOT <teos>\n",
              "2  <sos> list the five star rated movies starring...  <tsos> O O B-RATINGS_AVERAGE I-RATINGS_AVERAGE...\n",
              "3  <sos> what science fiction films have come out...     <tsos> O B-GENRE I-GENRE O O O O B-YEAR <teos>\n",
              "4  <sos> did the same director make all of the ha...    <tsos> O O O O O O O O B-TITLE I-TITLE O <teos>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zee7lgADwA8e"
      },
      "source": [
        "test_data = test_data.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msHz5g4stVOl"
      },
      "source": [
        "val_data = train_data[:int(N*val_split),0:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNr7SCJXtVLB",
        "outputId": "1a931409-dd2d-4c39-e96a-e503b768c2c2"
      },
      "source": [
        "print(val_data.shape[0]+train_data.shape[0],N,test_data.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9775 9775 2443\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wfd4GChxtcpE",
        "outputId": "0bb99f2e-acd9-4d6f-8b53-98ddc1d42d6c"
      },
      "source": [
        "print(train_data.shape)\n",
        "print(val_data.shape)\n",
        "print(test_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7820, 2)\n",
            "(1955, 2)\n",
            "(2443, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRay7_eptch_"
      },
      "source": [
        "train_d , train_l = [i.split(' ') for i in train_data[:,0]], [i.split(' ') for i in train_data[:,1]]\n",
        "val_d , val_l = [i.split(' ') for i in val_data[:,0]], [i.split(' ') for i in val_data[:,1]]\n",
        "test_d , test_l = [i.split(' ') for i in test_data[:,0]], [i.split(' ') for i in test_data[:,1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13G010BOtj63",
        "outputId": "6b563736-27a5-4520-e4e4-b5d186e1cfd3"
      },
      "source": [
        "max_length = 32\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_d + val_d)\n",
        "sequences = tokenizer.texts_to_sequences(train_d + val_d)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print(\"unique tokens except pad_token- \"+str(len(word_index)))\n",
        "vocab_size = len(tokenizer.word_index) + 1  #  with pad_token\n",
        "print('vocab_size - '+str(vocab_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unique tokens except pad_token- 5971\n",
            "vocab_size - 5972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q58celZvtj3v",
        "outputId": "2097566d-e972-4edd-c9ea-21163a275008"
      },
      "source": [
        "padded_lines = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "x_train_pad = padded_lines[0:-len(val_d)]\n",
        "x_val_pad = padded_lines[-len(val_d):]\n",
        "print(type(x_train_pad))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRNTj3-dtj05"
      },
      "source": [
        "test_sequences = tokenizer.texts_to_sequences(test_d)\n",
        "x_test_pad = pad_sequences(test_sequences, maxlen=max_length, padding = 'post')\n",
        "X_test_pad = []\n",
        "test_L = []\n",
        "for k,i in enumerate(x_test_pad):\n",
        "  if np.all(i==0)==False:\n",
        "    X_test_pad.append(i)\n",
        "    test_L.append(test_l[k])\n",
        "\n",
        "x_test_pad = np.array(X_test_pad)\n",
        "# test_l = np.array(test_L)\n",
        "\n",
        "# label_sequences = label_tokenizer.texts_to_sequences(test_L)\n",
        "# y_test_pad = pad_sequences(label_sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "# print(type(y_test_pad))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQOEdv9vtjy3",
        "outputId": "5a80029a-1f3b-4314-b62e-126967a97944"
      },
      "source": [
        "label_tokenizer = Tokenizer()\n",
        "label_tokenizer.fit_on_texts(train_l + val_l)\n",
        "label_sequences = label_tokenizer.texts_to_sequences(train_l + val_l)\n",
        "\n",
        "label_index = label_tokenizer.word_index\n",
        "print(\"unique tokens except pad_token- \"+str(len(label_index)))\n",
        "label_vocab_size = len(label_tokenizer.word_index) + 1  #  pad_token at 0th index\n",
        "print('vocab_size - '+str(label_vocab_size))\n",
        "# label_index[\"<pad>\"] = 0\n",
        "\n",
        "padded_lines = pad_sequences(label_sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "y_train_pad = padded_lines[0:-len(val_d)]\n",
        "y_val_pad = padded_lines[-len(val_d):]\n",
        "print(type(y_train_pad))\n",
        "\n",
        "\n",
        "label_sequences = label_tokenizer.texts_to_sequences(test_L)\n",
        "y_test_pad = pad_sequences(label_sequences, maxlen=max_length, padding='post')\n",
        "print(type(y_test_pad))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unique tokens except pad_token- 27\n",
            "vocab_size - 28\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gt0b5w5tu4S",
        "outputId": "83b00e96-50e9-4152-82d6-2e58fe425f20"
      },
      "source": [
        "label_tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'<teos>': 3,\n",
              " '<tsos>': 2,\n",
              " 'b-actor': 6,\n",
              " 'b-character': 21,\n",
              " 'b-director': 17,\n",
              " 'b-genre': 4,\n",
              " 'b-plot': 12,\n",
              " 'b-rating': 13,\n",
              " 'b-ratings_average': 15,\n",
              " 'b-review': 24,\n",
              " 'b-song': 23,\n",
              " 'b-title': 10,\n",
              " 'b-trailer': 26,\n",
              " 'b-year': 8,\n",
              " 'i-actor': 5,\n",
              " 'i-character': 22,\n",
              " 'i-director': 14,\n",
              " 'i-genre': 19,\n",
              " 'i-plot': 11,\n",
              " 'i-rating': 18,\n",
              " 'i-ratings_average': 16,\n",
              " 'i-review': 25,\n",
              " 'i-song': 20,\n",
              " 'i-title': 7,\n",
              " 'i-trailer': 27,\n",
              " 'i-year': 9,\n",
              " 'o': 1}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yqamWNKqxUe",
        "outputId": "a8a81c14-13f5-4396-ec52-8ad5c9b35ec1"
      },
      "source": [
        "import time\n",
        "SEED = 1234\n",
        "\n",
        "np.random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True    \n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')    \n",
        "\n",
        "batch_size = 512\n",
        "size = x_train_pad.shape[0]\n",
        "d = int(size/batch_size)\n",
        "X_train_b = np.array_split(x_train_pad,d)\n",
        "y_train_b = np.array_split(y_train_pad,d)\n",
        "\n",
        "class BahdanauAttention(nn.Module):\n",
        "    \"\"\"Implements Bahdanau (MLP) attention\"\"\"\n",
        "    \n",
        "    def __init__(self, hidden_size, key_size=None, query_size=None):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        \n",
        "        # We assume a bi-directional encoder so key_size is 2*hidden_size\n",
        "        key_size = 2 * hidden_size if key_size is None else key_size\n",
        "        query_size = hidden_size if query_size is None else query_size\n",
        "\n",
        "        self.key_layer = nn.Linear(key_size, hidden_size, bias=False)\n",
        "        self.query_layer = nn.Linear(query_size, hidden_size, bias=False)\n",
        "        self.energy_layer = nn.Linear(hidden_size, 1, bias=False)\n",
        "        \n",
        "        # to store attention scores\n",
        "        self.alphas = None\n",
        "        \n",
        "    def forward(self, query=None, key=None, value=None, mask=None):\n",
        "        assert mask is not None, \"mask is required\"\n",
        "\n",
        "        # We first project the query (the decoder state).\n",
        "        # The projected keys (the encoder states) were already pre-computated.\n",
        "        query = self.query_layer(query)\n",
        "        proj_key = self.key_layer(key)\n",
        "        # Calculate scores.\n",
        "        scores = self.energy_layer(torch.tanh(query.unsqueeze(1) + proj_key))\n",
        "        scores = scores.squeeze(2).unsqueeze(1)\n",
        "        \n",
        "        # Mask out invalid positions.\n",
        "        # The mask marks valid positions so we invert it using `mask & 0`.\n",
        "\n",
        "        \n",
        "        scores.data.masked_fill_(mask == 0, -float('inf'))\n",
        "        \n",
        "        # Turn scores to probabilities.\n",
        "        alphas = F.softmax(scores, dim=-1)\n",
        "        self.alphas = alphas        \n",
        "        \n",
        "        # The context vector is the weighted sum of the values.\n",
        "        context = torch.bmm(alphas, value)\n",
        "        \n",
        "        # context shape: [B, 1, 2D], alphas shape: [B, 1, M]\n",
        "        return context, alphas\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout,bidirectional=True,batch_first=True)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        #embedded = [batch size, src len, emb dim]\n",
        "        \n",
        "        outputs, (hidden, cell) = self.rnn(embedded)\n",
        "        #outputs = [batch size, src len, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #outputs are always from the top hidden layer\n",
        "        h1 = (hidden[0,:,:] + hidden[1,:,:])/2\n",
        "        #h2 = (hidden[2,:,:] + hidden[3,:,:])/2\n",
        "        #h = torch.stack((h1,h2),dim=0)\n",
        "        c1 = (cell[0,:,:] + cell[1,:,:])/2\n",
        "        #c2 = (cell[2,:,:] + cell[3,:,:])/2\n",
        "        #c = torch.stack((c1,c2),dim=0)\n",
        "        return outputs, c1.unsqueeze(0)\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.output_dim = output_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        # self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        input_dim = output_dim + hid_dim*2 #(*2 for bidirectioanl enc)\n",
        "        self.rnn = nn.LSTM(input_dim, hid_dim, n_layers, dropout = dropout, batch_first=True)\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input,attn, hidden, cell):\n",
        "        \n",
        "        #input = [batch size]\n",
        "        #hidden = [batch size, n layers * n directions, hid dim]\n",
        "        #cell = [batch size, n layers * n directions, hid dim]\n",
        "        \n",
        "        #n directions in the decoder will both always be 1, therefore:\n",
        "        #hidden = [n layers, batch size, hid dim]\n",
        "        #context = [n layers, batch size, hid dim]\n",
        "        \n",
        "        \n",
        "        #input = [batch size,]\n",
        "        \n",
        "        input_onehot =  torch.nn.functional.one_hot(input,num_classes=self.output_dim)\n",
        "\n",
        "        #input_onehot = [batch_size,output_dim]\n",
        "\n",
        "        # attn = [batch_size,hid_dim*2] (*2 for bidirectioanl enc)\n",
        "\n",
        "        concat_input = torch.cat((input_onehot,attn),dim=1).unsqueeze(1)\n",
        "        # concat_input = [batch_size,1,output_dim + hid_dim*2]\n",
        "        output, (hidden, cell) = self.rnn(concat_input, (hidden, cell))\n",
        "        \n",
        "        #output = [batch size, seq len, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #seq len and n directions will always be 1 in the decoder, therefore:\n",
        "        #output = [1, batch size, hid dim]\n",
        "        #hidden = [n layers, batch size, hid dim]\n",
        "        #cell = [n layers, batch size, hid dim]\n",
        "        prediction = self.fc_out(output.squeeze(1))\n",
        "        \n",
        "        #prediction = [batch size, output dim]\n",
        "        \n",
        "        return prediction, hidden, cell\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, attention, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        self.attention = attention\n",
        "        \n",
        "\n",
        "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
        "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        #assert encoder.n_layers == decoder.n_layers, \\\n",
        "        #    \"Encoder and decoder must have equal number of layers!\"\n",
        "        \n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        #src = [ batch size, src len]\n",
        "        #trg = [ batch size, trg len]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
        "        \n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        trg_hid_dim = self.decoder.hid_dim\n",
        "        src_hid_dim = self.encoder.hid_dim*2  # *2 for bidirectional encoder\n",
        "        n_layer = self.decoder.n_layers\n",
        "        \n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
        "        outputs_e, cell = self.encoder(src.long())\n",
        "        hidden = torch.zeros((n_layer,batch_size,trg_hid_dim)).to(device)\n",
        "        \n",
        "        attn, alpha = self.attention(hidden.squeeze(0),outputs_e,outputs_e,src.unsqueeze(1))  # key and value are same for Bahdanau attention\n",
        "        #first input to the decoder\n",
        "        input = trg[:,0]\n",
        "        for t in range(1, trg_len):\n",
        "            \n",
        "            #insert input token embedding, previous hidden and previous cell states\n",
        "            #receive output tensor (predictions) and new hidden and cell states\n",
        "            output, hidden, cell = self.decoder(input.long(),attn.squeeze(1), hidden, cell)\n",
        "            attn, alpha = self.attention(hidden.squeeze(0),outputs_e,outputs_e,src.unsqueeze(1))\n",
        "            #place predictions in a tensor holding predictions for each token\n",
        "            outputs[:,t] = output\n",
        "            #decide if we are going to use teacher forcing or not\n",
        "            teacher_force = np.random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1) \n",
        "            \n",
        "            #if teacher forcing, use actual next token as next input\n",
        "            #if not, use predicted token\n",
        "            input = trg[:,t] if teacher_force else top1\n",
        "        \n",
        "        return outputs\n",
        "\n",
        "\n",
        "INPUT_DIM = vocab_size\n",
        "OUTPUT_DIM = label_vocab_size\n",
        "ENC_EMB_DIM = 100\n",
        "# DEC_EMB_DIM = \n",
        "HID_DIM = 32\n",
        "N_LAYERS = 1\n",
        "ENC_DROPOUT = 0.25\n",
        "DEC_DROPOUT = 0.25\n",
        "\n",
        "\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT).to(device)\n",
        "attention = BahdanauAttention(HID_DIM).to(device)\n",
        "dec = Decoder(OUTPUT_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT).to(device)\n",
        "\n",
        "model = Seq2Seq(enc, dec, attention, device).to(device)\n",
        "\n",
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "        \n",
        "#model.apply(init_weights)\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.05)\n",
        "\n",
        "TRG_PAD_IDX = 0\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
        "\n",
        "def train(model, X, y, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    n_samples = 0\n",
        "    n_trg = 0\n",
        "    correct = 0\n",
        "    \n",
        "    for src,trg in zip(X,y):\n",
        "        \n",
        "        src,trg = torch.from_numpy(src).to(device),torch.from_numpy(trg).to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg)\n",
        "        #trg = [batch size, trg len]\n",
        "        #output = [batch size, trg len, output dim]\n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output_1 = output.view(-1, output_dim)\n",
        "        trg_1 = trg.view(-1)\n",
        "        \n",
        "        #trg_1 = [(trg len) * batch size]\n",
        "        #output_1 = [(trg len) * batch size, output dim]\n",
        "\n",
        "        mask = torch.logical_not(torch.eq(trg.long(), torch.tensor(0)))  # =>[batch, seq_Len], each element is a bool value, and if there is a pad in the sequence, the corresponding position of the mask is False\n",
        "        mask = mask.type(torch.bool)\n",
        "        \n",
        "        pred = torch.argmax(output,2)\n",
        "        \n",
        "        pred = torch.masked_select(pred,mask)\n",
        "        true = torch.masked_select(trg.long(),mask)\n",
        "        n_trg += true.shape[0]\n",
        "\n",
        "        correct += torch.sum(true==pred)\n",
        "        \n",
        "        loss = criterion(output_1, trg_1.long())\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        #torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()*true.shape[0]\n",
        "        n_samples += trg.shape[0]\n",
        "    return epoch_loss / n_trg , correct.float()/n_trg\n",
        "\n",
        "def evaluate(model, X, y, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "                                           \n",
        "        src,trg = X, y\n",
        "        \n",
        "        src, trg = torch.from_numpy(np.array(src)).to(device),  torch.from_numpy(np.array(trg)).to(device)\n",
        "                                           \n",
        "        output = model(src, trg, 0) #turn off teacher forcing\n",
        "\n",
        "        #trg = [trg len, batch size]\n",
        "        #output = [trg len, batch size, output dim]\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "\n",
        "        output_1 = output.view(-1, output_dim)\n",
        "        trg_1 = trg.view(-1)\n",
        "\n",
        "        #trg_1 = [(trg len - 1) * batch size]\n",
        "        #output_1 = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "        loss = criterion(output_1, trg_1.long())\n",
        "\n",
        "        epoch_loss = loss.item()\n",
        "        \n",
        "        mask = torch.logical_not(torch.eq(trg.long(), torch.tensor(0)))  # =>[batch, seq_Len], each element is a bool value, and if there is a pad in the sequence, the corresponding position of the mask is False\n",
        "        mask = mask.type(torch.bool)\n",
        "        \n",
        "        pred = torch.argmax(output,2)\n",
        "        pred = torch.masked_select(pred,mask)\n",
        "        true = torch.masked_select(trg.long(),mask)\n",
        "        \n",
        "        acc = torch.sum(true==pred).float()/true.shape[0]\n",
        "\n",
        "    return epoch_loss, acc\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    \n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "N_EPOCHS = 100\n",
        "CLIP = 1\n",
        "val_losses = []\n",
        "train_losses = []\n",
        "val_accs = []\n",
        "train_accs = []\n",
        "best_valid_acc = 0\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    train_loss,train_acc = train(model, X_train_b, y_train_b, optimizer, criterion, CLIP)\n",
        "    valid_loss,valid_acc = evaluate(model, x_val_pad, y_val_pad, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_acc > best_valid_acc:\n",
        "        best_valid_acc = valid_acc\n",
        "        torch.save(model, './seq2seq_attn_ner.sav')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | \\t Train Acc: {train_acc: 3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} | \\t Valid Acc: {valid_acc: 3f}')\n",
        "\n",
        "    val_losses.append(valid_loss)\n",
        "    val_accs.append(valid_acc)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    \n",
        "    \n",
        "model = torch.load('./seq2seq_attn_ner.sav')\n",
        "\n",
        "test_loss,test_acc = evaluate(model, x_test_pad, y_test_pad, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | \\t Test Acc: {test_acc: 3f}')\n",
        "\n",
        "\n",
        "\n",
        "plt.title('Loss vs Epochs')\n",
        "plt.plot(val_losses,label='valid')\n",
        "plt.plot(train_losses,label='train')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(val_accs,label='valid_acc')\n",
        "plt.plot(train_accs,label='train_acc')\n",
        "plt.legend()\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model has 651,660 trainable parameters\n",
            "Epoch: 01 | Time: 0m 12s\n",
            "\tTrain Loss: 2.126 | \t Train Acc:  0.499172\n",
            "\t Val. Loss: 2.063 | \t Valid Acc:  0.499643\n",
            "| Test Loss: 2.021 | \t Test Acc:  0.504702\n",
            "Epoch: 02 | Time: 0m 12s\n",
            "\tTrain Loss: 1.927 | \t Train Acc:  0.512256\n",
            "\t Val. Loss: 2.015 | \t Valid Acc:  0.499691\n",
            "| Test Loss: 1.986 | \t Test Acc:  0.505074\n",
            "Epoch: 03 | Time: 0m 12s\n",
            "\tTrain Loss: 1.888 | \t Train Acc:  0.522534\n",
            "\t Val. Loss: 1.967 | \t Valid Acc:  0.507677\n",
            "| Test Loss: 1.955 | \t Test Acc:  0.496820\n",
            "Epoch: 04 | Time: 0m 12s\n",
            "\tTrain Loss: 1.851 | \t Train Acc:  0.534760\n",
            "\t Val. Loss: 1.961 | \t Valid Acc:  0.506631\n",
            "| Test Loss: 1.949 | \t Test Acc:  0.493742\n",
            "Epoch: 05 | Time: 0m 12s\n",
            "\tTrain Loss: 1.817 | \t Train Acc:  0.541979\n",
            "\t Val. Loss: 1.923 | \t Valid Acc:  0.517707\n",
            "| Test Loss: 1.922 | \t Test Acc:  0.503484\n",
            "Epoch: 06 | Time: 0m 12s\n",
            "\tTrain Loss: 1.795 | \t Train Acc:  0.541948\n",
            "\t Val. Loss: 1.885 | \t Valid Acc:  0.530256\n",
            "| Test Loss: 1.879 | \t Test Acc:  0.518976\n",
            "Epoch: 07 | Time: 0m 12s\n",
            "\tTrain Loss: 1.766 | \t Train Acc:  0.546683\n",
            "\t Val. Loss: 1.848 | \t Valid Acc:  0.544564\n",
            "| Test Loss: 1.840 | \t Test Acc:  0.533825\n",
            "Epoch: 08 | Time: 0m 12s\n",
            "\tTrain Loss: 1.744 | \t Train Acc:  0.547340\n",
            "\t Val. Loss: 1.863 | \t Valid Acc:  0.536578\n",
            "| Test Loss: 1.865 | \t Test Acc:  0.520126\n",
            "Epoch: 09 | Time: 0m 12s\n",
            "\tTrain Loss: 1.722 | \t Train Acc:  0.549016\n",
            "\t Val. Loss: 1.805 | \t Valid Acc:  0.557827\n",
            "| Test Loss: 1.797 | \t Test Acc:  0.543127\n",
            "Epoch: 10 | Time: 0m 12s\n",
            "\tTrain Loss: 1.697 | \t Train Acc:  0.552065\n",
            "\t Val. Loss: 1.818 | \t Valid Acc:  0.550887\n",
            "| Test Loss: 1.808 | \t Test Acc:  0.538865\n",
            "Epoch: 11 | Time: 0m 12s\n",
            "\tTrain Loss: 1.680 | \t Train Acc:  0.553690\n",
            "\t Val. Loss: 1.796 | \t Valid Acc:  0.555545\n",
            "| Test Loss: 1.791 | \t Test Acc:  0.541368\n",
            "Epoch: 12 | Time: 0m 12s\n",
            "\tTrain Loss: 1.657 | \t Train Acc:  0.558617\n",
            "\t Val. Loss: 1.835 | \t Valid Acc:  0.540191\n",
            "| Test Loss: 1.823 | \t Test Acc:  0.528447\n",
            "Epoch: 13 | Time: 0m 12s\n",
            "\tTrain Loss: 1.648 | \t Train Acc:  0.557214\n",
            "\t Val. Loss: 1.739 | \t Valid Acc:  0.567524\n",
            "| Test Loss: 1.735 | \t Test Acc:  0.551718\n",
            "Epoch: 14 | Time: 0m 12s\n",
            "\tTrain Loss: 1.627 | \t Train Acc:  0.562150\n",
            "\t Val. Loss: 1.734 | \t Valid Acc:  0.565527\n",
            "| Test Loss: 1.730 | \t Test Acc:  0.554560\n",
            "Epoch: 15 | Time: 0m 12s\n",
            "\tTrain Loss: 1.606 | \t Train Acc:  0.563665\n",
            "\t Val. Loss: 1.740 | \t Valid Acc:  0.560489\n",
            "| Test Loss: 1.729 | \t Test Acc:  0.554221\n",
            "Epoch: 16 | Time: 0m 12s\n",
            "\tTrain Loss: 1.589 | \t Train Acc:  0.565462\n",
            "\t Val. Loss: 1.779 | \t Valid Acc:  0.550078\n",
            "| Test Loss: 1.761 | \t Test Acc:  0.543499\n",
            "Epoch: 17 | Time: 0m 12s\n",
            "\tTrain Loss: 1.567 | \t Train Acc:  0.571156\n",
            "\t Val. Loss: 1.757 | \t Valid Acc:  0.556543\n",
            "| Test Loss: 1.740 | \t Test Acc:  0.549249\n",
            "Epoch: 18 | Time: 0m 12s\n",
            "\tTrain Loss: 1.551 | \t Train Acc:  0.573417\n",
            "\t Val. Loss: 1.736 | \t Valid Acc:  0.555022\n",
            "| Test Loss: 1.716 | \t Test Acc:  0.550602\n",
            "Epoch: 19 | Time: 0m 12s\n",
            "\tTrain Loss: 1.526 | \t Train Acc:  0.579687\n",
            "\t Val. Loss: 1.772 | \t Valid Acc:  0.550982\n",
            "| Test Loss: 1.750 | \t Test Acc:  0.545055\n",
            "Epoch: 20 | Time: 0m 12s\n",
            "\tTrain Loss: 1.511 | \t Train Acc:  0.583735\n",
            "\t Val. Loss: 1.690 | \t Valid Acc:  0.554642\n",
            "| Test Loss: 1.676 | \t Test Acc:  0.552361\n",
            "Epoch: 21 | Time: 0m 12s\n",
            "\tTrain Loss: 1.488 | \t Train Acc:  0.588349\n",
            "\t Val. Loss: 1.756 | \t Valid Acc:  0.550174\n",
            "| Test Loss: 1.741 | \t Test Acc:  0.544378\n",
            "Epoch: 22 | Time: 0m 12s\n",
            "\tTrain Loss: 1.482 | \t Train Acc:  0.589692\n",
            "\t Val. Loss: 1.694 | \t Valid Acc:  0.564909\n",
            "| Test Loss: 1.681 | \t Test Acc:  0.556724\n",
            "Epoch: 23 | Time: 0m 12s\n",
            "\tTrain Loss: 1.464 | \t Train Acc:  0.595134\n",
            "\t Val. Loss: 1.701 | \t Valid Acc:  0.559966\n",
            "| Test Loss: 1.681 | \t Test Acc:  0.555608\n",
            "Epoch: 24 | Time: 0m 12s\n",
            "\tTrain Loss: 1.443 | \t Train Acc:  0.601676\n",
            "\t Val. Loss: 1.637 | \t Valid Acc:  0.572800\n",
            "| Test Loss: 1.633 | \t Test Acc:  0.563286\n",
            "Epoch: 25 | Time: 0m 13s\n",
            "\tTrain Loss: 1.427 | \t Train Acc:  0.602928\n",
            "\t Val. Loss: 1.729 | \t Valid Acc:  0.557066\n",
            "| Test Loss: 1.709 | \t Test Acc:  0.549148\n",
            "Epoch: 26 | Time: 0m 12s\n",
            "\tTrain Loss: 1.410 | \t Train Acc:  0.603362\n",
            "\t Val. Loss: 1.632 | \t Valid Acc:  0.575700\n",
            "| Test Loss: 1.627 | \t Test Acc:  0.562407\n",
            "Epoch: 27 | Time: 0m 12s\n",
            "\tTrain Loss: 1.374 | \t Train Acc:  0.616002\n",
            "\t Val. Loss: 1.618 | \t Valid Acc:  0.574036\n",
            "| Test Loss: 1.632 | \t Test Acc:  0.559802\n",
            "Epoch: 28 | Time: 0m 12s\n",
            "\tTrain Loss: 1.385 | \t Train Acc:  0.609470\n",
            "\t Val. Loss: 1.567 | \t Valid Acc:  0.581452\n",
            "| Test Loss: 1.595 | \t Test Acc:  0.563760\n",
            "Epoch: 29 | Time: 0m 12s\n",
            "\tTrain Loss: 1.360 | \t Train Acc:  0.615366\n",
            "\t Val. Loss: 1.568 | \t Valid Acc:  0.579360\n",
            "| Test Loss: 1.581 | \t Test Acc:  0.568022\n",
            "Epoch: 30 | Time: 0m 12s\n",
            "\tTrain Loss: 1.352 | \t Train Acc:  0.616638\n",
            "\t Val. Loss: 1.542 | \t Valid Acc:  0.584494\n",
            "| Test Loss: 1.570 | \t Test Acc:  0.567007\n",
            "Epoch: 31 | Time: 0m 12s\n",
            "\tTrain Loss: 1.325 | \t Train Acc:  0.624008\n",
            "\t Val. Loss: 1.583 | \t Valid Acc:  0.580168\n",
            "| Test Loss: 1.580 | \t Test Acc:  0.569307\n",
            "Epoch: 32 | Time: 0m 12s\n",
            "\tTrain Loss: 1.328 | \t Train Acc:  0.618486\n",
            "\t Val. Loss: 1.535 | \t Valid Acc:  0.586348\n",
            "| Test Loss: 1.570 | \t Test Acc:  0.568123\n",
            "Epoch: 33 | Time: 0m 12s\n",
            "\tTrain Loss: 1.301 | \t Train Acc:  0.626159\n",
            "\t Val. Loss: 1.526 | \t Valid Acc:  0.593858\n",
            "| Test Loss: 1.532 | \t Test Acc:  0.580875\n",
            "Epoch: 34 | Time: 0m 12s\n",
            "\tTrain Loss: 1.295 | \t Train Acc:  0.627612\n",
            "\t Val. Loss: 1.495 | \t Valid Acc:  0.591434\n",
            "| Test Loss: 1.528 | \t Test Acc:  0.576681\n",
            "Epoch: 35 | Time: 0m 12s\n",
            "\tTrain Loss: 1.281 | \t Train Acc:  0.630893\n",
            "\t Val. Loss: 1.543 | \t Valid Acc:  0.580976\n",
            "| Test Loss: 1.528 | \t Test Acc:  0.579928\n",
            "Epoch: 36 | Time: 0m 12s\n",
            "\tTrain Loss: 1.268 | \t Train Acc:  0.632468\n",
            "\t Val. Loss: 1.487 | \t Valid Acc:  0.588297\n",
            "| Test Loss: 1.537 | \t Test Acc:  0.572554\n",
            "Epoch: 37 | Time: 0m 12s\n",
            "\tTrain Loss: 1.266 | \t Train Acc:  0.632246\n",
            "\t Val. Loss: 1.480 | \t Valid Acc:  0.593668\n",
            "| Test Loss: 1.519 | \t Test Acc:  0.578305\n",
            "Epoch: 38 | Time: 0m 12s\n",
            "\tTrain Loss: 1.247 | \t Train Acc:  0.635729\n",
            "\t Val. Loss: 1.503 | \t Valid Acc:  0.596520\n",
            "| Test Loss: 1.508 | \t Test Acc:  0.585915\n",
            "Epoch: 39 | Time: 0m 12s\n",
            "\tTrain Loss: 1.235 | \t Train Acc:  0.640899\n",
            "\t Val. Loss: 1.459 | \t Valid Acc:  0.599040\n",
            "| Test Loss: 1.513 | \t Test Acc:  0.579658\n",
            "Epoch: 40 | Time: 0m 12s\n",
            "\tTrain Loss: 1.208 | \t Train Acc:  0.646330\n",
            "\t Val. Loss: 1.423 | \t Valid Acc:  0.610020\n",
            "| Test Loss: 1.474 | \t Test Acc:  0.590549\n",
            "Epoch: 41 | Time: 0m 12s\n",
            "\tTrain Loss: 1.200 | \t Train Acc:  0.648582\n",
            "\t Val. Loss: 1.489 | \t Valid Acc:  0.590674\n",
            "| Test Loss: 1.545 | \t Test Acc:  0.574618\n",
            "Epoch: 42 | Time: 0m 13s\n",
            "\tTrain Loss: 1.223 | \t Train Acc:  0.641484\n",
            "\t Val. Loss: 1.464 | \t Valid Acc:  0.597994\n",
            "| Test Loss: 1.462 | \t Test Acc:  0.595082\n",
            "Epoch: 43 | Time: 0m 12s\n",
            "\tTrain Loss: 1.181 | \t Train Acc:  0.653074\n",
            "\t Val. Loss: 1.414 | \t Valid Acc:  0.613586\n",
            "| Test Loss: 1.464 | \t Test Acc:  0.593864\n",
            "Epoch: 44 | Time: 0m 12s\n",
            "\tTrain Loss: 1.167 | \t Train Acc:  0.655467\n",
            "\t Val. Loss: 1.401 | \t Valid Acc:  0.609117\n",
            "| Test Loss: 1.471 | \t Test Acc:  0.590718\n",
            "Epoch: 45 | Time: 0m 13s\n",
            "\tTrain Loss: 1.164 | \t Train Acc:  0.656749\n",
            "\t Val. Loss: 1.412 | \t Valid Acc:  0.615820\n",
            "| Test Loss: 1.453 | \t Test Acc:  0.598498\n",
            "Epoch: 46 | Time: 0m 13s\n",
            "\tTrain Loss: 1.152 | \t Train Acc:  0.661121\n",
            "\t Val. Loss: 1.367 | \t Valid Acc:  0.624138\n",
            "| Test Loss: 1.433 | \t Test Acc:  0.601103\n",
            "Epoch: 47 | Time: 0m 12s\n",
            "\tTrain Loss: 1.152 | \t Train Acc:  0.659758\n",
            "\t Val. Loss: 1.424 | \t Valid Acc:  0.608737\n",
            "| Test Loss: 1.493 | \t Test Acc:  0.587708\n",
            "Epoch: 48 | Time: 0m 12s\n",
            "\tTrain Loss: 1.113 | \t Train Acc:  0.668561\n",
            "\t Val. Loss: 1.379 | \t Valid Acc:  0.622903\n",
            "| Test Loss: 1.417 | \t Test Acc:  0.605906\n",
            "Epoch: 49 | Time: 0m 13s\n",
            "\tTrain Loss: 1.124 | \t Train Acc:  0.666340\n",
            "\t Val. Loss: 1.379 | \t Valid Acc:  0.613871\n",
            "| Test Loss: 1.457 | \t Test Acc:  0.594270\n",
            "Epoch: 50 | Time: 0m 13s\n",
            "\tTrain Loss: 1.116 | \t Train Acc:  0.667451\n",
            "\t Val. Loss: 1.371 | \t Valid Acc:  0.621524\n",
            "| Test Loss: 1.400 | \t Test Acc:  0.610912\n",
            "Epoch: 51 | Time: 0m 12s\n",
            "\tTrain Loss: 1.097 | \t Train Acc:  0.673054\n",
            "\t Val. Loss: 1.351 | \t Valid Acc:  0.616390\n",
            "| Test Loss: 1.446 | \t Test Acc:  0.597585\n",
            "Epoch: 52 | Time: 0m 12s\n",
            "\tTrain Loss: 1.087 | \t Train Acc:  0.675952\n",
            "\t Val. Loss: 1.369 | \t Valid Acc:  0.619480\n",
            "| Test Loss: 1.380 | \t Test Acc:  0.615884\n",
            "Epoch: 53 | Time: 0m 12s\n",
            "\tTrain Loss: 1.079 | \t Train Acc:  0.677395\n",
            "\t Val. Loss: 1.355 | \t Valid Acc:  0.616485\n",
            "| Test Loss: 1.450 | \t Test Acc:  0.597754\n",
            "Epoch: 54 | Time: 0m 12s\n",
            "\tTrain Loss: 1.062 | \t Train Acc:  0.681111\n",
            "\t Val. Loss: 1.356 | \t Valid Acc:  0.626373\n",
            "| Test Loss: 1.391 | \t Test Acc:  0.612265\n",
            "Epoch: 55 | Time: 0m 12s\n",
            "\tTrain Loss: 1.068 | \t Train Acc:  0.680475\n",
            "\t Val. Loss: 1.283 | \t Valid Acc:  0.636307\n",
            "| Test Loss: 1.369 | \t Test Acc:  0.616392\n",
            "Epoch: 56 | Time: 0m 12s\n",
            "\tTrain Loss: 1.045 | \t Train Acc:  0.687885\n",
            "\t Val. Loss: 1.309 | \t Valid Acc:  0.634786\n",
            "| Test Loss: 1.351 | \t Test Acc:  0.621634\n",
            "Epoch: 57 | Time: 0m 12s\n",
            "\tTrain Loss: 1.044 | \t Train Acc:  0.687521\n",
            "\t Val. Loss: 1.354 | \t Valid Acc:  0.617483\n",
            "| Test Loss: 1.450 | \t Test Acc:  0.598701\n",
            "Epoch: 58 | Time: 0m 12s\n",
            "\tTrain Loss: 1.035 | \t Train Acc:  0.687481\n",
            "\t Val. Loss: 1.275 | \t Valid Acc:  0.643200\n",
            "| Test Loss: 1.329 | \t Test Acc:  0.626370\n",
            "Epoch: 59 | Time: 0m 12s\n",
            "\tTrain Loss: 1.030 | \t Train Acc:  0.690379\n",
            "\t Val. Loss: 1.316 | \t Valid Acc:  0.627466\n",
            "| Test Loss: 1.404 | \t Test Acc:  0.609559\n",
            "Epoch: 60 | Time: 0m 13s\n",
            "\tTrain Loss: 1.003 | \t Train Acc:  0.697627\n",
            "\t Val. Loss: 1.251 | \t Valid Acc:  0.645482\n",
            "| Test Loss: 1.288 | \t Test Acc:  0.637803\n",
            "Epoch: 61 | Time: 0m 14s\n",
            "\tTrain Loss: 0.999 | \t Train Acc:  0.699808\n",
            "\t Val. Loss: 1.251 | \t Valid Acc:  0.643818\n",
            "| Test Loss: 1.356 | \t Test Acc:  0.622345\n",
            "Epoch: 62 | Time: 0m 13s\n",
            "\tTrain Loss: 0.991 | \t Train Acc:  0.702958\n",
            "\t Val. Loss: 1.237 | \t Valid Acc:  0.647478\n",
            "| Test Loss: 1.334 | \t Test Acc:  0.629448\n",
            "Epoch: 63 | Time: 0m 14s\n",
            "\tTrain Loss: 0.959 | \t Train Acc:  0.710530\n",
            "\t Val. Loss: 1.225 | \t Valid Acc:  0.656082\n",
            "| Test Loss: 1.295 | \t Test Acc:  0.637938\n",
            "Epoch: 64 | Time: 0m 14s\n",
            "\tTrain Loss: 0.990 | \t Train Acc:  0.698879\n",
            "\t Val. Loss: 1.217 | \t Valid Acc:  0.653373\n",
            "| Test Loss: 1.315 | \t Test Acc:  0.632086\n",
            "Epoch: 65 | Time: 0m 14s\n",
            "\tTrain Loss: 0.951 | \t Train Acc:  0.713801\n",
            "\t Val. Loss: 1.174 | \t Valid Acc:  0.669630\n",
            "| Test Loss: 1.253 | \t Test Acc:  0.647984\n",
            "Epoch: 66 | Time: 0m 13s\n",
            "\tTrain Loss: 0.948 | \t Train Acc:  0.712509\n",
            "\t Val. Loss: 1.239 | \t Valid Acc:  0.646100\n",
            "| Test Loss: 1.353 | \t Test Acc:  0.625321\n",
            "Epoch: 67 | Time: 0m 12s\n",
            "\tTrain Loss: 0.932 | \t Train Acc:  0.718849\n",
            "\t Val. Loss: 1.157 | \t Valid Acc:  0.674668\n",
            "| Test Loss: 1.247 | \t Test Acc:  0.652381\n",
            "Epoch: 68 | Time: 0m 12s\n",
            "\tTrain Loss: 0.927 | \t Train Acc:  0.718708\n",
            "\t Val. Loss: 1.215 | \t Valid Acc:  0.650758\n",
            "| Test Loss: 1.334 | \t Test Acc:  0.631038\n",
            "Epoch: 69 | Time: 0m 12s\n",
            "\tTrain Loss: 0.921 | \t Train Acc:  0.720969\n",
            "\t Val. Loss: 1.171 | \t Valid Acc:  0.671151\n",
            "| Test Loss: 1.254 | \t Test Acc:  0.652111\n",
            "Epoch: 70 | Time: 0m 12s\n",
            "\tTrain Loss: 0.922 | \t Train Acc:  0.720000\n",
            "\t Val. Loss: 1.195 | \t Valid Acc:  0.659980\n",
            "| Test Loss: 1.299 | \t Test Acc:  0.642673\n",
            "Epoch: 71 | Time: 0m 12s\n",
            "\tTrain Loss: 0.903 | \t Train Acc:  0.725734\n",
            "\t Val. Loss: 1.130 | \t Valid Acc:  0.681894\n",
            "| Test Loss: 1.217 | \t Test Acc:  0.661582\n",
            "Epoch: 72 | Time: 0m 12s\n",
            "\tTrain Loss: 0.895 | \t Train Acc:  0.728026\n",
            "\t Val. Loss: 1.125 | \t Valid Acc:  0.675809\n",
            "| Test Loss: 1.260 | \t Test Acc:  0.649100\n",
            "Epoch: 73 | Time: 0m 12s\n",
            "\tTrain Loss: 0.900 | \t Train Acc:  0.727108\n",
            "\t Val. Loss: 1.114 | \t Valid Acc:  0.684223\n",
            "| Test Loss: 1.202 | \t Test Acc:  0.666080\n",
            "Epoch: 74 | Time: 0m 12s\n",
            "\tTrain Loss: 0.877 | \t Train Acc:  0.733791\n",
            "\t Val. Loss: 1.131 | \t Valid Acc:  0.675524\n",
            "| Test Loss: 1.257 | \t Test Acc:  0.651705\n",
            "Epoch: 75 | Time: 0m 12s\n",
            "\tTrain Loss: 0.852 | \t Train Acc:  0.742504\n",
            "\t Val. Loss: 1.116 | \t Valid Acc:  0.678947\n",
            "| Test Loss: 1.188 | \t Test Acc:  0.666114\n",
            "Epoch: 76 | Time: 0m 12s\n",
            "\tTrain Loss: 0.877 | \t Train Acc:  0.731792\n",
            "\t Val. Loss: 1.138 | \t Valid Acc:  0.667110\n",
            "| Test Loss: 1.286 | \t Test Acc:  0.643181\n",
            "Epoch: 77 | Time: 0m 12s\n",
            "\tTrain Loss: 0.856 | \t Train Acc:  0.739637\n",
            "\t Val. Loss: 1.057 | \t Valid Acc:  0.700860\n",
            "| Test Loss: 1.179 | \t Test Acc:  0.671289\n",
            "Epoch: 78 | Time: 0m 12s\n",
            "\tTrain Loss: 0.857 | \t Train Acc:  0.738788\n",
            "\t Val. Loss: 1.098 | \t Valid Acc:  0.681133\n",
            "| Test Loss: 1.250 | \t Test Acc:  0.656102\n",
            "Epoch: 79 | Time: 0m 12s\n",
            "\tTrain Loss: 0.852 | \t Train Acc:  0.737476\n",
            "\t Val. Loss: 1.042 | \t Valid Acc:  0.706327\n",
            "| Test Loss: 1.165 | \t Test Acc:  0.675720\n",
            "Epoch: 80 | Time: 0m 12s\n",
            "\tTrain Loss: 0.818 | \t Train Acc:  0.750621\n",
            "\t Val. Loss: 1.055 | \t Valid Acc:  0.698579\n",
            "| Test Loss: 1.204 | \t Test Acc:  0.670410\n",
            "Epoch: 81 | Time: 0m 12s\n",
            "\tTrain Loss: 0.807 | \t Train Acc:  0.754720\n",
            "\t Val. Loss: 1.032 | \t Valid Acc:  0.708704\n",
            "| Test Loss: 1.154 | \t Test Acc:  0.681268\n",
            "Epoch: 82 | Time: 0m 12s\n",
            "\tTrain Loss: 0.832 | \t Train Acc:  0.742342\n",
            "\t Val. Loss: 1.063 | \t Valid Acc:  0.690498\n",
            "| Test Loss: 1.233 | \t Test Acc:  0.660736\n",
            "Epoch: 83 | Time: 0m 12s\n",
            "\tTrain Loss: 0.807 | \t Train Acc:  0.753337\n",
            "\t Val. Loss: 1.014 | \t Valid Acc:  0.714788\n",
            "| Test Loss: 1.148 | \t Test Acc:  0.682519\n",
            "Epoch: 84 | Time: 0m 12s\n",
            "\tTrain Loss: 0.790 | \t Train Acc:  0.760071\n",
            "\t Val. Loss: 1.040 | \t Valid Acc:  0.696772\n",
            "| Test Loss: 1.234 | \t Test Acc:  0.659924\n",
            "Epoch: 85 | Time: 0m 12s\n",
            "\tTrain Loss: 0.815 | \t Train Acc:  0.748753\n",
            "\t Val. Loss: 0.986 | \t Valid Acc:  0.721491\n",
            "| Test Loss: 1.132 | \t Test Acc:  0.687830\n",
            "Epoch: 86 | Time: 0m 12s\n",
            "\tTrain Loss: 0.805 | \t Train Acc:  0.753145\n",
            "\t Val. Loss: 1.002 | \t Valid Acc:  0.710035\n",
            "| Test Loss: 1.186 | \t Test Acc:  0.673522\n",
            "Epoch: 87 | Time: 0m 12s\n",
            "\tTrain Loss: 0.766 | \t Train Acc:  0.767794\n",
            "\t Val. Loss: 1.005 | \t Valid Acc:  0.716357\n",
            "| Test Loss: 1.131 | \t Test Acc:  0.688540\n",
            "Epoch: 88 | Time: 0m 12s\n",
            "\tTrain Loss: 0.782 | \t Train Acc:  0.760545\n",
            "\t Val. Loss: 0.977 | \t Valid Acc:  0.720112\n",
            "| Test Loss: 1.154 | \t Test Acc:  0.684921\n",
            "Epoch: 89 | Time: 0m 12s\n",
            "\tTrain Loss: 0.772 | \t Train Acc:  0.763756\n",
            "\t Val. Loss: 1.007 | \t Valid Acc:  0.706422\n",
            "| Test Loss: 1.199 | \t Test Acc:  0.675754\n",
            "Epoch: 90 | Time: 0m 12s\n",
            "\tTrain Loss: 0.767 | \t Train Acc:  0.764291\n",
            "\t Val. Loss: 0.988 | \t Valid Acc:  0.719257\n",
            "| Test Loss: 1.122 | \t Test Acc:  0.692633\n",
            "Epoch: 91 | Time: 0m 12s\n",
            "\tTrain Loss: 0.794 | \t Train Acc:  0.753619\n",
            "\t Val. Loss: 0.954 | \t Valid Acc:  0.722537\n",
            "| Test Loss: 1.158 | \t Test Acc:  0.683331\n",
            "Epoch: 92 | Time: 0m 12s\n",
            "\tTrain Loss: 0.752 | \t Train Acc:  0.772539\n",
            "\t Val. Loss: 0.965 | \t Valid Acc:  0.727670\n",
            "| Test Loss: 1.115 | \t Test Acc:  0.696421\n",
            "Epoch: 93 | Time: 0m 12s\n",
            "\tTrain Loss: 0.742 | \t Train Acc:  0.773216\n",
            "\t Val. Loss: 1.039 | \t Valid Acc:  0.703855\n",
            "| Test Loss: 1.239 | \t Test Acc:  0.669226\n",
            "Epoch: 94 | Time: 0m 12s\n",
            "\tTrain Loss: 0.750 | \t Train Acc:  0.770419\n",
            "\t Val. Loss: 0.926 | \t Valid Acc:  0.736607\n",
            "| Test Loss: 1.086 | \t Test Acc:  0.701766\n",
            "Epoch: 95 | Time: 0m 12s\n",
            "\tTrain Loss: 0.760 | \t Train Acc:  0.764533\n",
            "\t Val. Loss: 0.934 | \t Valid Acc:  0.731711\n",
            "| Test Loss: 1.132 | \t Test Acc:  0.695440\n",
            "Epoch: 96 | Time: 0m 12s\n",
            "\tTrain Loss: 0.713 | \t Train Acc:  0.783311\n",
            "\t Val. Loss: 0.943 | \t Valid Acc:  0.728383\n",
            "| Test Loss: 1.093 | \t Test Acc:  0.698755\n",
            "Epoch: 97 | Time: 0m 12s\n",
            "\tTrain Loss: 0.726 | \t Train Acc:  0.776355\n",
            "\t Val. Loss: 0.936 | \t Valid Acc:  0.729714\n",
            "| Test Loss: 1.161 | \t Test Acc:  0.688100\n",
            "Epoch: 98 | Time: 0m 12s\n",
            "\tTrain Loss: 0.701 | \t Train Acc:  0.788178\n",
            "\t Val. Loss: 0.913 | \t Valid Acc:  0.741741\n",
            "| Test Loss: 1.092 | \t Test Acc:  0.706095\n",
            "Epoch: 99 | Time: 0m 12s\n",
            "\tTrain Loss: 0.758 | \t Train Acc:  0.764654\n",
            "\t Val. Loss: 0.933 | \t Valid Acc:  0.735561\n",
            "| Test Loss: 1.141 | \t Test Acc:  0.696861\n",
            "Epoch: 100 | Time: 0m 12s\n",
            "\tTrain Loss: 0.700 | \t Train Acc:  0.788794\n",
            "\t Val. Loss: 0.908 | \t Valid Acc:  0.748206\n",
            "| Test Loss: 1.096 | \t Test Acc:  0.709985\n",
            "Epoch: 101 | Time: 0m 12s\n",
            "\tTrain Loss: 0.723 | \t Train Acc:  0.778001\n",
            "\t Val. Loss: 0.887 | \t Valid Acc:  0.747540\n",
            "| Test Loss: 1.113 | \t Test Acc:  0.704844\n",
            "Epoch: 102 | Time: 0m 12s\n",
            "\tTrain Loss: 0.747 | \t Train Acc:  0.766562\n",
            "\t Val. Loss: 0.891 | \t Valid Acc:  0.745401\n",
            "| Test Loss: 1.072 | \t Test Acc:  0.708632\n",
            "Epoch: 103 | Time: 0m 13s\n",
            "\tTrain Loss: 0.686 | \t Train Acc:  0.790308\n",
            "\t Val. Loss: 0.905 | \t Valid Acc:  0.740790\n",
            "| Test Loss: 1.134 | \t Test Acc:  0.701935\n",
            "Epoch: 104 | Time: 0m 13s\n",
            "\tTrain Loss: 0.667 | \t Train Acc:  0.797577\n",
            "\t Val. Loss: 0.886 | \t Valid Acc:  0.750059\n",
            "| Test Loss: 1.065 | \t Test Acc:  0.719050\n",
            "Epoch: 105 | Time: 0m 12s\n",
            "\tTrain Loss: 0.701 | \t Train Acc:  0.783847\n",
            "\t Val. Loss: 0.863 | \t Valid Acc:  0.757903\n",
            "| Test Loss: 1.080 | \t Test Acc:  0.716344\n",
            "Epoch: 106 | Time: 0m 12s\n",
            "\tTrain Loss: 0.709 | \t Train Acc:  0.779929\n",
            "\t Val. Loss: 0.890 | \t Valid Acc:  0.745639\n",
            "| Test Loss: 1.065 | \t Test Acc:  0.710831\n",
            "Epoch: 107 | Time: 0m 12s\n",
            "\tTrain Loss: 0.706 | \t Train Acc:  0.781837\n",
            "\t Val. Loss: 0.873 | \t Valid Acc:  0.749869\n",
            "| Test Loss: 1.106 | \t Test Acc:  0.710662\n",
            "Epoch: 108 | Time: 0m 12s\n",
            "\tTrain Loss: 0.636 | \t Train Acc:  0.810712\n",
            "\t Val. Loss: 0.842 | \t Valid Acc:  0.763084\n",
            "| Test Loss: 1.055 | \t Test Acc:  0.722399\n",
            "Epoch: 109 | Time: 0m 12s\n",
            "\tTrain Loss: 0.688 | \t Train Acc:  0.789167\n",
            "\t Val. Loss: 0.828 | \t Valid Acc:  0.767933\n",
            "| Test Loss: 1.075 | \t Test Acc:  0.719050\n",
            "Epoch: 110 | Time: 0m 12s\n",
            "\tTrain Loss: 0.718 | \t Train Acc:  0.776002\n",
            "\t Val. Loss: 0.829 | \t Valid Acc:  0.765603\n",
            "| Test Loss: 1.059 | \t Test Acc:  0.719219\n",
            "Epoch: 111 | Time: 0m 14s\n",
            "\tTrain Loss: 0.641 | \t Train Acc:  0.804230\n",
            "\t Val. Loss: 0.832 | \t Valid Acc:  0.766887\n",
            "| Test Loss: 1.068 | \t Test Acc:  0.719287\n",
            "Epoch: 112 | Time: 0m 12s\n",
            "\tTrain Loss: 0.681 | \t Train Acc:  0.790560\n",
            "\t Val. Loss: 0.862 | \t Valid Acc:  0.753007\n",
            "| Test Loss: 1.118 | \t Test Acc:  0.708395\n",
            "Epoch: 113 | Time: 0m 12s\n",
            "\tTrain Loss: 0.650 | \t Train Acc:  0.800172\n",
            "\t Val. Loss: 0.831 | \t Valid Acc:  0.764177\n",
            "| Test Loss: 1.036 | \t Test Acc:  0.720674\n",
            "Epoch: 114 | Time: 0m 12s\n",
            "\tTrain Loss: 0.636 | \t Train Acc:  0.806623\n",
            "\t Val. Loss: 0.834 | \t Valid Acc:  0.762276\n",
            "| Test Loss: 1.107 | \t Test Acc:  0.716818\n",
            "Epoch: 115 | Time: 0m 12s\n",
            "\tTrain Loss: 0.650 | \t Train Acc:  0.799233\n",
            "\t Val. Loss: 0.815 | \t Valid Acc:  0.769787\n",
            "| Test Loss: 1.096 | \t Test Acc:  0.717528\n",
            "Epoch: 116 | Time: 0m 12s\n",
            "\tTrain Loss: 0.618 | \t Train Acc:  0.811843\n",
            "\t Val. Loss: 0.817 | \t Valid Acc:  0.768741\n",
            "| Test Loss: 1.105 | \t Test Acc:  0.719997\n",
            "Epoch: 117 | Time: 0m 12s\n",
            "\tTrain Loss: 0.664 | \t Train Acc:  0.794639\n",
            "\t Val. Loss: 0.795 | \t Valid Acc:  0.779817\n",
            "| Test Loss: 1.054 | \t Test Acc:  0.728623\n",
            "Epoch: 118 | Time: 0m 12s\n",
            "\tTrain Loss: 0.650 | \t Train Acc:  0.799445\n",
            "\t Val. Loss: 0.790 | \t Valid Acc:  0.779341\n",
            "| Test Loss: 1.062 | \t Test Acc:  0.727743\n",
            "Epoch: 119 | Time: 0m 12s\n",
            "\tTrain Loss: 0.613 | \t Train Acc:  0.813428\n",
            "\t Val. Loss: 0.795 | \t Valid Acc:  0.776537\n",
            "| Test Loss: 1.083 | \t Test Acc:  0.725815\n",
            "Epoch: 120 | Time: 0m 12s\n",
            "\tTrain Loss: 0.641 | \t Train Acc:  0.802837\n",
            "\t Val. Loss: 0.869 | \t Valid Acc:  0.745401\n",
            "| Test Loss: 1.053 | \t Test Acc:  0.715465\n",
            "Epoch: 121 | Time: 0m 13s\n",
            "\tTrain Loss: 0.604 | \t Train Acc:  0.816870\n",
            "\t Val. Loss: 0.819 | \t Valid Acc:  0.765746\n",
            "| Test Loss: 1.128 | \t Test Acc:  0.716581\n",
            "Epoch: 122 | Time: 0m 13s\n",
            "\tTrain Loss: 0.599 | \t Train Acc:  0.817850\n",
            "\t Val. Loss: 0.773 | \t Valid Acc:  0.784142\n",
            "| Test Loss: 1.074 | \t Test Acc:  0.731329\n",
            "Epoch: 123 | Time: 0m 12s\n",
            "\tTrain Loss: 0.662 | \t Train Acc:  0.797910\n",
            "\t Val. Loss: 0.772 | \t Valid Acc:  0.784190\n",
            "| Test Loss: 1.057 | \t Test Acc:  0.731904\n",
            "Epoch: 124 | Time: 0m 12s\n",
            "\tTrain Loss: 0.647 | \t Train Acc:  0.800273\n",
            "\t Val. Loss: 0.780 | \t Valid Acc:  0.779103\n",
            "| Test Loss: 1.020 | \t Test Acc:  0.733290\n",
            "Epoch: 125 | Time: 0m 12s\n",
            "\tTrain Loss: 0.566 | \t Train Acc:  0.830459\n",
            "\t Val. Loss: 0.765 | \t Valid Acc:  0.785426\n",
            "| Test Loss: 1.070 | \t Test Acc:  0.735388\n",
            "Epoch: 126 | Time: 0m 12s\n",
            "\tTrain Loss: 0.635 | \t Train Acc:  0.804109\n",
            "\t Val. Loss: 0.769 | \t Valid Acc:  0.784475\n",
            "| Test Loss: 1.039 | \t Test Acc:  0.732513\n",
            "Epoch: 127 | Time: 0m 12s\n",
            "\tTrain Loss: 0.650 | \t Train Acc:  0.797415\n",
            "\t Val. Loss: 0.753 | \t Valid Acc:  0.787042\n",
            "| Test Loss: 1.066 | \t Test Acc:  0.732343\n",
            "Epoch: 128 | Time: 0m 12s\n",
            "\tTrain Loss: 0.574 | \t Train Acc:  0.827774\n",
            "\t Val. Loss: 0.739 | \t Valid Acc:  0.794790\n",
            "| Test Loss: 1.039 | \t Test Acc:  0.738702\n",
            "Epoch: 129 | Time: 0m 12s\n",
            "\tTrain Loss: 0.621 | \t Train Acc:  0.808470\n",
            "\t Val. Loss: 0.745 | \t Valid Acc:  0.791225\n",
            "| Test Loss: 1.053 | \t Test Acc:  0.735049\n",
            "Epoch: 130 | Time: 0m 12s\n",
            "\tTrain Loss: 0.591 | \t Train Acc:  0.819838\n",
            "\t Val. Loss: 0.771 | \t Valid Acc:  0.779436\n",
            "| Test Loss: 1.034 | \t Test Acc:  0.733493\n",
            "Epoch: 131 | Time: 0m 12s\n",
            "\tTrain Loss: 0.596 | \t Train Acc:  0.818052\n",
            "\t Val. Loss: 0.748 | \t Valid Acc:  0.788325\n",
            "| Test Loss: 1.062 | \t Test Acc:  0.738567\n",
            "Epoch: 132 | Time: 0m 12s\n",
            "\tTrain Loss: 0.638 | \t Train Acc:  0.801373\n",
            "\t Val. Loss: 0.752 | \t Valid Acc:  0.786424\n",
            "| Test Loss: 1.025 | \t Test Acc:  0.735049\n",
            "Epoch: 133 | Time: 0m 12s\n",
            "\tTrain Loss: 0.553 | \t Train Acc:  0.834841\n",
            "\t Val. Loss: 0.753 | \t Valid Acc:  0.784808\n",
            "| Test Loss: 1.100 | \t Test Acc:  0.730889\n",
            "Epoch: 134 | Time: 0m 12s\n",
            "\tTrain Loss: 0.568 | \t Train Acc:  0.826704\n",
            "\t Val. Loss: 0.735 | \t Valid Acc:  0.791035\n",
            "| Test Loss: 1.037 | \t Test Acc:  0.737925\n",
            "Epoch: 135 | Time: 0m 12s\n",
            "\tTrain Loss: 0.567 | \t Train Acc:  0.828551\n",
            "\t Val. Loss: 0.746 | \t Valid Acc:  0.789846\n",
            "| Test Loss: 1.038 | \t Test Acc:  0.742119\n",
            "Epoch: 136 | Time: 0m 12s\n",
            "\tTrain Loss: 0.607 | \t Train Acc:  0.813367\n",
            "\t Val. Loss: 0.722 | \t Valid Acc:  0.797785\n",
            "| Test Loss: 1.053 | \t Test Acc:  0.742761\n",
            "Epoch: 137 | Time: 0m 12s\n",
            "\tTrain Loss: 0.594 | \t Train Acc:  0.815901\n",
            "\t Val. Loss: 0.732 | \t Valid Acc:  0.796264\n",
            "| Test Loss: 1.037 | \t Test Acc:  0.742051\n",
            "Epoch: 138 | Time: 0m 12s\n",
            "\tTrain Loss: 0.544 | \t Train Acc:  0.837143\n",
            "\t Val. Loss: 0.710 | \t Valid Acc:  0.799354\n",
            "| Test Loss: 1.051 | \t Test Acc:  0.745197\n",
            "Epoch: 139 | Time: 0m 12s\n",
            "\tTrain Loss: 0.596 | \t Train Acc:  0.816143\n",
            "\t Val. Loss: 0.733 | \t Valid Acc:  0.789609\n",
            "| Test Loss: 1.090 | \t Test Acc:  0.735624\n",
            "Epoch: 140 | Time: 0m 12s\n",
            "\tTrain Loss: 0.570 | \t Train Acc:  0.824483\n",
            "\t Val. Loss: 0.806 | \t Valid Acc:  0.758045\n",
            "| Test Loss: 1.028 | \t Test Acc:  0.728454\n",
            "Epoch: 141 | Time: 0m 12s\n",
            "\tTrain Loss: 0.547 | \t Train Acc:  0.835134\n",
            "\t Val. Loss: 0.720 | \t Valid Acc:  0.796787\n",
            "| Test Loss: 1.087 | \t Test Acc:  0.738702\n",
            "Epoch: 142 | Time: 0m 12s\n",
            "\tTrain Loss: 0.546 | \t Train Acc:  0.834154\n",
            "\t Val. Loss: 0.696 | \t Valid Acc:  0.805058\n",
            "| Test Loss: 1.043 | \t Test Acc:  0.745806\n",
            "Epoch: 143 | Time: 0m 12s\n",
            "\tTrain Loss: 0.623 | \t Train Acc:  0.812034\n",
            "\t Val. Loss: 0.709 | \t Valid Acc:  0.802443\n",
            "| Test Loss: 1.062 | \t Test Acc:  0.741645\n",
            "Epoch: 144 | Time: 0m 12s\n",
            "\tTrain Loss: 0.528 | \t Train Acc:  0.841656\n",
            "\t Val. Loss: 0.685 | \t Valid Acc:  0.808480\n",
            "| Test Loss: 1.027 | \t Test Acc:  0.749729\n",
            "Epoch: 145 | Time: 0m 12s\n",
            "\tTrain Loss: 0.570 | \t Train Acc:  0.827249\n",
            "\t Val. Loss: 0.769 | \t Valid Acc:  0.776394\n",
            "| Test Loss: 1.027 | \t Test Acc:  0.736538\n",
            "Epoch: 146 | Time: 0m 12s\n",
            "\tTrain Loss: 0.523 | \t Train Acc:  0.841848\n",
            "\t Val. Loss: 0.763 | \t Valid Acc:  0.781813\n",
            "| Test Loss: 1.148 | \t Test Acc:  0.729265\n",
            "Epoch: 147 | Time: 0m 12s\n",
            "\tTrain Loss: 0.548 | \t Train Acc:  0.833559\n",
            "\t Val. Loss: 0.672 | \t Valid Acc:  0.814612\n",
            "| Test Loss: 1.025 | \t Test Acc:  0.751894\n",
            "Epoch: 148 | Time: 0m 12s\n",
            "\tTrain Loss: 0.581 | \t Train Acc:  0.821161\n",
            "\t Val. Loss: 0.688 | \t Valid Acc:  0.808195\n",
            "| Test Loss: 1.035 | \t Test Acc:  0.749662\n",
            "Epoch: 149 | Time: 0m 12s\n",
            "\tTrain Loss: 0.552 | \t Train Acc:  0.833286\n",
            "\t Val. Loss: 0.685 | \t Valid Acc:  0.806864\n",
            "| Test Loss: 1.011 | \t Test Acc:  0.750169\n",
            "Epoch: 150 | Time: 0m 12s\n",
            "\tTrain Loss: 0.506 | \t Train Acc:  0.849086\n",
            "\t Val. Loss: 0.673 | \t Valid Acc:  0.811903\n",
            "| Test Loss: 1.026 | \t Test Acc:  0.753924\n",
            "Epoch: 151 | Time: 0m 12s\n",
            "\tTrain Loss: 0.548 | \t Train Acc:  0.834064\n",
            "\t Val. Loss: 0.672 | \t Valid Acc:  0.810239\n",
            "| Test Loss: 1.045 | \t Test Acc:  0.748613\n",
            "Epoch: 152 | Time: 0m 12s\n",
            "\tTrain Loss: 0.530 | \t Train Acc:  0.839364\n",
            "\t Val. Loss: 0.655 | \t Valid Acc:  0.817845\n",
            "| Test Loss: 1.027 | \t Test Acc:  0.754600\n",
            "Epoch: 153 | Time: 0m 12s\n",
            "\tTrain Loss: 0.561 | \t Train Acc:  0.829329\n",
            "\t Val. Loss: 0.655 | \t Valid Acc:  0.816371\n",
            "| Test Loss: 1.012 | \t Test Acc:  0.751657\n",
            "Epoch: 154 | Time: 0m 12s\n",
            "\tTrain Loss: 0.576 | \t Train Acc:  0.824351\n",
            "\t Val. Loss: 0.663 | \t Valid Acc:  0.814327\n",
            "| Test Loss: 1.048 | \t Test Acc:  0.749323\n",
            "Epoch: 155 | Time: 0m 12s\n",
            "\tTrain Loss: 0.499 | \t Train Acc:  0.852196\n",
            "\t Val. Loss: 0.663 | \t Valid Acc:  0.813281\n",
            "| Test Loss: 1.028 | \t Test Acc:  0.755040\n",
            "Epoch: 156 | Time: 0m 12s\n",
            "\tTrain Loss: 0.557 | \t Train Acc:  0.828824\n",
            "\t Val. Loss: 0.653 | \t Valid Acc:  0.816086\n",
            "| Test Loss: 1.063 | \t Test Acc:  0.746922\n",
            "Epoch: 157 | Time: 0m 12s\n",
            "\tTrain Loss: 0.561 | \t Train Acc:  0.827420\n",
            "\t Val. Loss: 0.682 | \t Valid Acc:  0.805295\n",
            "| Test Loss: 1.023 | \t Test Acc:  0.748207\n",
            "Epoch: 158 | Time: 0m 12s\n",
            "\tTrain Loss: 0.513 | \t Train Acc:  0.845977\n",
            "\t Val. Loss: 0.647 | \t Valid Acc:  0.817750\n",
            "| Test Loss: 1.050 | \t Test Acc:  0.752199\n",
            "Epoch: 159 | Time: 0m 12s\n",
            "\tTrain Loss: 0.523 | \t Train Acc:  0.841343\n",
            "\t Val. Loss: 0.796 | \t Valid Acc:  0.764795\n",
            "| Test Loss: 1.081 | \t Test Acc:  0.723752\n",
            "Epoch: 160 | Time: 0m 12s\n",
            "\tTrain Loss: 0.490 | \t Train Acc:  0.853761\n",
            "\t Val. Loss: 0.673 | \t Valid Acc:  0.808195\n",
            "| Test Loss: 1.107 | \t Test Acc:  0.742660\n",
            "Epoch: 161 | Time: 0m 12s\n",
            "\tTrain Loss: 0.484 | \t Train Acc:  0.856275\n",
            "\t Val. Loss: 0.647 | \t Valid Acc:  0.816466\n",
            "| Test Loss: 1.027 | \t Test Acc:  0.754837\n",
            "Epoch: 162 | Time: 0m 12s\n",
            "\tTrain Loss: 0.582 | \t Train Acc:  0.822352\n",
            "\t Val. Loss: 0.660 | \t Valid Acc:  0.813044\n",
            "| Test Loss: 1.073 | \t Test Acc:  0.746820\n",
            "Epoch: 163 | Time: 0m 12s\n",
            "\tTrain Loss: 0.525 | \t Train Acc:  0.842191\n",
            "\t Val. Loss: 0.640 | \t Valid Acc:  0.819841\n",
            "| Test Loss: 1.032 | \t Test Acc:  0.755378\n",
            "Epoch: 164 | Time: 0m 12s\n",
            "\tTrain Loss: 0.477 | \t Train Acc:  0.857617\n",
            "\t Val. Loss: 0.627 | \t Valid Acc:  0.824405\n",
            "| Test Loss: 1.032 | \t Test Acc:  0.756900\n",
            "Epoch: 165 | Time: 0m 12s\n",
            "\tTrain Loss: 0.507 | \t Train Acc:  0.846138\n",
            "\t Val. Loss: 0.648 | \t Valid Acc:  0.814755\n",
            "| Test Loss: 1.033 | \t Test Acc:  0.753247\n",
            "Epoch: 166 | Time: 0m 12s\n",
            "\tTrain Loss: 0.604 | \t Train Acc:  0.819253\n",
            "\t Val. Loss: 0.641 | \t Valid Acc:  0.818748\n",
            "| Test Loss: 1.070 | \t Test Acc:  0.748850\n",
            "Epoch: 167 | Time: 0m 12s\n",
            "\tTrain Loss: 0.489 | \t Train Acc:  0.853922\n",
            "\t Val. Loss: 0.617 | \t Valid Acc:  0.825545\n",
            "| Test Loss: 1.022 | \t Test Acc:  0.760959\n",
            "Epoch: 168 | Time: 0m 12s\n",
            "\tTrain Loss: 0.465 | \t Train Acc:  0.862726\n",
            "\t Val. Loss: 0.682 | \t Valid Acc:  0.801873\n",
            "| Test Loss: 1.045 | \t Test Acc:  0.749053\n",
            "Epoch: 169 | Time: 0m 13s\n",
            "\tTrain Loss: 0.523 | \t Train Acc:  0.844533\n",
            "\t Val. Loss: 0.639 | \t Valid Acc:  0.817464\n",
            "| Test Loss: 1.070 | \t Test Acc:  0.754330\n",
            "Epoch: 170 | Time: 0m 12s\n",
            "\tTrain Loss: 0.504 | \t Train Acc:  0.847340\n",
            "\t Val. Loss: 0.616 | \t Valid Acc:  0.826544\n",
            "| Test Loss: 1.043 | \t Test Acc:  0.758152\n",
            "Epoch: 171 | Time: 0m 12s\n",
            "\tTrain Loss: 0.502 | \t Train Acc:  0.849369\n",
            "\t Val. Loss: 0.602 | \t Valid Acc:  0.830869\n",
            "| Test Loss: 1.032 | \t Test Acc:  0.760249\n",
            "Epoch: 172 | Time: 0m 12s\n",
            "\tTrain Loss: 0.525 | \t Train Acc:  0.841353\n",
            "\t Val. Loss: 0.630 | \t Valid Acc:  0.821125\n",
            "| Test Loss: 1.014 | \t Test Acc:  0.756258\n",
            "Epoch: 173 | Time: 0m 12s\n",
            "\tTrain Loss: 0.505 | \t Train Acc:  0.849409\n",
            "\t Val. Loss: 0.641 | \t Valid Acc:  0.815896\n",
            "| Test Loss: 1.012 | \t Test Acc:  0.753958\n",
            "Epoch: 174 | Time: 0m 12s\n",
            "\tTrain Loss: 0.458 | \t Train Acc:  0.865068\n",
            "\t Val. Loss: 0.603 | \t Valid Acc:  0.830156\n",
            "| Test Loss: 1.050 | \t Test Acc:  0.759505\n",
            "Epoch: 175 | Time: 0m 12s\n",
            "\tTrain Loss: 0.493 | \t Train Acc:  0.850924\n",
            "\t Val. Loss: 0.599 | \t Valid Acc:  0.831582\n",
            "| Test Loss: 1.037 | \t Test Acc:  0.760283\n",
            "Epoch: 176 | Time: 0m 13s\n",
            "\tTrain Loss: 0.561 | \t Train Acc:  0.830944\n",
            "\t Val. Loss: 0.608 | \t Valid Acc:  0.828112\n",
            "| Test Loss: 1.011 | \t Test Acc:  0.757069\n",
            "Epoch: 177 | Time: 0m 12s\n",
            "\tTrain Loss: 0.459 | \t Train Acc:  0.864250\n",
            "\t Val. Loss: 0.592 | \t Valid Acc:  0.833769\n",
            "| Test Loss: 1.025 | \t Test Acc:  0.763530\n",
            "Epoch: 178 | Time: 0m 12s\n",
            "\tTrain Loss: 0.458 | \t Train Acc:  0.863998\n",
            "\t Val. Loss: 0.604 | \t Valid Acc:  0.831012\n",
            "| Test Loss: 1.044 | \t Test Acc:  0.762008\n",
            "Epoch: 179 | Time: 0m 12s\n",
            "\tTrain Loss: 0.539 | \t Train Acc:  0.841898\n",
            "\t Val. Loss: 0.610 | \t Valid Acc:  0.830489\n",
            "| Test Loss: 1.030 | \t Test Acc:  0.754397\n",
            "Epoch: 180 | Time: 0m 12s\n",
            "\tTrain Loss: 0.446 | \t Train Acc:  0.868723\n",
            "\t Val. Loss: 0.601 | \t Valid Acc:  0.830156\n",
            "| Test Loss: 1.029 | \t Test Acc:  0.763902\n",
            "Epoch: 181 | Time: 0m 12s\n",
            "\tTrain Loss: 0.453 | \t Train Acc:  0.865936\n",
            "\t Val. Loss: 0.592 | \t Valid Acc:  0.833246\n",
            "| Test Loss: 1.028 | \t Test Acc:  0.763834\n",
            "Epoch: 182 | Time: 0m 12s\n",
            "\tTrain Loss: 0.550 | \t Train Acc:  0.836810\n",
            "\t Val. Loss: 0.605 | \t Valid Acc:  0.827352\n",
            "| Test Loss: 1.092 | \t Test Acc:  0.748546\n",
            "Epoch: 183 | Time: 0m 12s\n",
            "\tTrain Loss: 0.518 | \t Train Acc:  0.840949\n",
            "\t Val. Loss: 0.595 | \t Valid Acc:  0.832533\n",
            "| Test Loss: 1.011 | \t Test Acc:  0.763226\n",
            "Epoch: 184 | Time: 0m 12s\n",
            "\tTrain Loss: 0.437 | \t Train Acc:  0.872549\n",
            "\t Val. Loss: 0.585 | \t Valid Acc:  0.834815\n",
            "| Test Loss: 1.028 | \t Test Acc:  0.764714\n",
            "Epoch: 185 | Time: 0m 12s\n",
            "\tTrain Loss: 0.442 | \t Train Acc:  0.870106\n",
            "\t Val. Loss: 0.613 | \t Valid Acc:  0.826068\n",
            "| Test Loss: 1.039 | \t Test Acc:  0.762278\n",
            "Epoch: 186 | Time: 0m 12s\n",
            "\tTrain Loss: 0.553 | \t Train Acc:  0.834255\n",
            "\t Val. Loss: 0.595 | \t Valid Acc:  0.830917\n",
            "| Test Loss: 1.083 | \t Test Acc:  0.754059\n",
            "Epoch: 187 | Time: 0m 12s\n",
            "\tTrain Loss: 0.461 | \t Train Acc:  0.861676\n",
            "\t Val. Loss: 0.592 | \t Valid Acc:  0.832771\n",
            "| Test Loss: 1.030 | \t Test Acc:  0.762921\n",
            "Epoch: 188 | Time: 0m 12s\n",
            "\tTrain Loss: 0.437 | \t Train Acc:  0.870793\n",
            "\t Val. Loss: 0.568 | \t Valid Acc:  0.839901\n",
            "| Test Loss: 1.041 | \t Test Acc:  0.766337\n",
            "Epoch: 189 | Time: 0m 12s\n",
            "\tTrain Loss: 0.462 | \t Train Acc:  0.860737\n",
            "\t Val. Loss: 0.584 | \t Valid Acc:  0.835623\n",
            "| Test Loss: 1.028 | \t Test Acc:  0.763226\n",
            "Epoch: 190 | Time: 0m 12s\n",
            "\tTrain Loss: 0.506 | \t Train Acc:  0.847390\n",
            "\t Val. Loss: 0.598 | \t Valid Acc:  0.829443\n",
            "| Test Loss: 1.096 | \t Test Acc:  0.753924\n",
            "Epoch: 191 | Time: 0m 12s\n",
            "\tTrain Loss: 0.441 | \t Train Acc:  0.869076\n",
            "\t Val. Loss: 0.570 | \t Valid Acc:  0.838285\n",
            "| Test Loss: 1.019 | \t Test Acc:  0.767115\n",
            "Epoch: 192 | Time: 0m 12s\n",
            "\tTrain Loss: 0.436 | \t Train Acc:  0.870893\n",
            "\t Val. Loss: 0.697 | \t Valid Acc:  0.799354\n",
            "| Test Loss: 1.240 | \t Test Acc:  0.727946\n",
            "Epoch: 193 | Time: 0m 12s\n",
            "\tTrain Loss: 0.508 | \t Train Acc:  0.850570\n",
            "\t Val. Loss: 0.600 | \t Valid Acc:  0.828968\n",
            "| Test Loss: 1.028 | \t Test Acc:  0.759809\n",
            "Epoch: 194 | Time: 0m 12s\n",
            "\tTrain Loss: 0.438 | \t Train Acc:  0.871388\n",
            "\t Val. Loss: 0.561 | \t Valid Acc:  0.841993\n",
            "| Test Loss: 1.010 | \t Test Acc:  0.768807\n",
            "Epoch: 195 | Time: 0m 12s\n",
            "\tTrain Loss: 0.522 | \t Train Acc:  0.847501\n",
            "\t Val. Loss: 0.601 | \t Valid Acc:  0.827732\n",
            "| Test Loss: 1.040 | \t Test Acc:  0.757915\n",
            "Epoch: 196 | Time: 0m 12s\n",
            "\tTrain Loss: 0.431 | \t Train Acc:  0.873377\n",
            "\t Val. Loss: 0.573 | \t Valid Acc:  0.837049\n",
            "| Test Loss: 1.069 | \t Test Acc:  0.763902\n",
            "Epoch: 197 | Time: 0m 12s\n",
            "\tTrain Loss: 0.414 | \t Train Acc:  0.879011\n",
            "\t Val. Loss: 0.552 | \t Valid Acc:  0.844465\n",
            "| Test Loss: 1.033 | \t Test Acc:  0.769246\n",
            "Epoch: 198 | Time: 0m 12s\n",
            "\tTrain Loss: 0.518 | \t Train Acc:  0.845048\n",
            "\t Val. Loss: 0.585 | \t Valid Acc:  0.832913\n",
            "| Test Loss: 1.042 | \t Test Acc:  0.765187\n",
            "Epoch: 199 | Time: 0m 12s\n",
            "\tTrain Loss: 0.434 | \t Train Acc:  0.871378\n",
            "\t Val. Loss: 0.551 | \t Valid Acc:  0.844940\n",
            "| Test Loss: 1.033 | \t Test Acc:  0.767115\n",
            "Epoch: 200 | Time: 0m 12s\n",
            "\tTrain Loss: 0.419 | \t Train Acc:  0.876931\n",
            "\t Val. Loss: 0.549 | \t Valid Acc:  0.845273\n",
            "| Test Loss: 1.055 | \t Test Acc:  0.766912\n",
            "Epoch: 201 | Time: 0m 12s\n",
            "\tTrain Loss: 0.547 | \t Train Acc:  0.836850\n",
            "\t Val. Loss: 0.570 | \t Valid Acc:  0.838285\n",
            "| Test Loss: 1.079 | \t Test Acc:  0.759674\n",
            "Epoch: 202 | Time: 0m 12s\n",
            "\tTrain Loss: 0.501 | \t Train Acc:  0.852085\n",
            "\t Val. Loss: 0.575 | \t Valid Acc:  0.835148\n",
            "| Test Loss: 1.027 | \t Test Acc:  0.763767\n",
            "Epoch: 203 | Time: 0m 12s\n",
            "\tTrain Loss: 0.415 | \t Train Acc:  0.878344\n",
            "\t Val. Loss: 0.533 | \t Valid Acc:  0.848933\n",
            "| Test Loss: 1.037 | \t Test Acc:  0.770430\n",
            "Epoch: 204 | Time: 0m 12s\n",
            "\tTrain Loss: 0.486 | \t Train Acc:  0.854488\n",
            "\t Val. Loss: 0.586 | \t Valid Acc:  0.830584\n",
            "| Test Loss: 1.039 | \t Test Acc:  0.757577\n",
            "Epoch: 205 | Time: 0m 12s\n",
            "\tTrain Loss: 0.437 | \t Train Acc:  0.869288\n",
            "\t Val. Loss: 0.558 | \t Valid Acc:  0.838713\n",
            "| Test Loss: 1.075 | \t Test Acc:  0.762278\n",
            "Epoch: 206 | Time: 0m 12s\n",
            "\tTrain Loss: 0.415 | \t Train Acc:  0.877910\n",
            "\t Val. Loss: 0.562 | \t Valid Acc:  0.840852\n",
            "| Test Loss: 1.056 | \t Test Acc:  0.769246\n",
            "Epoch: 207 | Time: 0m 12s\n",
            "\tTrain Loss: 0.460 | \t Train Acc:  0.864634\n",
            "\t Val. Loss: 0.571 | \t Valid Acc:  0.832723\n",
            "| Test Loss: 1.095 | \t Test Acc:  0.755480\n",
            "Epoch: 208 | Time: 0m 12s\n",
            "\tTrain Loss: 0.415 | \t Train Acc:  0.877234\n",
            "\t Val. Loss: 0.663 | \t Valid Acc:  0.808052\n",
            "| Test Loss: 1.088 | \t Test Acc:  0.745637\n",
            "Epoch: 209 | Time: 0m 12s\n",
            "\tTrain Loss: 0.462 | \t Train Acc:  0.862554\n",
            "\t Val. Loss: 0.560 | \t Valid Acc:  0.840139\n",
            "| Test Loss: 1.076 | \t Test Acc:  0.765796\n",
            "Epoch: 210 | Time: 0m 12s\n",
            "\tTrain Loss: 0.408 | \t Train Acc:  0.880212\n",
            "\t Val. Loss: 0.532 | \t Valid Acc:  0.849788\n",
            "| Test Loss: 1.044 | \t Test Acc:  0.771242\n",
            "Epoch: 211 | Time: 0m 12s\n",
            "\tTrain Loss: 0.487 | \t Train Acc:  0.854801\n",
            "\t Val. Loss: 0.542 | \t Valid Acc:  0.846081\n",
            "| Test Loss: 1.061 | \t Test Acc:  0.763462\n",
            "Epoch: 212 | Time: 0m 12s\n",
            "\tTrain Loss: 0.470 | \t Train Acc:  0.860475\n",
            "\t Val. Loss: 0.527 | \t Valid Acc:  0.850026\n",
            "| Test Loss: 1.049 | \t Test Acc:  0.769010\n",
            "Epoch: 213 | Time: 0m 12s\n",
            "\tTrain Loss: 0.403 | \t Train Acc:  0.882807\n",
            "\t Val. Loss: 0.524 | \t Valid Acc:  0.850977\n",
            "| Test Loss: 1.046 | \t Test Acc:  0.770633\n",
            "Epoch: 214 | Time: 0m 12s\n",
            "\tTrain Loss: 0.402 | \t Train Acc:  0.881858\n",
            "\t Val. Loss: 0.520 | \t Valid Acc:  0.852831\n",
            "| Test Loss: 1.033 | \t Test Acc:  0.771073\n",
            "Epoch: 215 | Time: 0m 12s\n",
            "\tTrain Loss: 0.519 | \t Train Acc:  0.849177\n",
            "\t Val. Loss: 0.553 | \t Valid Acc:  0.841565\n",
            "| Test Loss: 1.115 | \t Test Acc:  0.756461\n",
            "Epoch: 216 | Time: 0m 12s\n",
            "\tTrain Loss: 0.459 | \t Train Acc:  0.864745\n",
            "\t Val. Loss: 0.555 | \t Valid Acc:  0.840234\n",
            "| Test Loss: 1.046 | \t Test Acc:  0.766845\n",
            "Epoch: 217 | Time: 0m 12s\n",
            "\tTrain Loss: 0.398 | \t Train Acc:  0.883513\n",
            "\t Val. Loss: 0.532 | \t Valid Acc:  0.848077\n",
            "| Test Loss: 1.047 | \t Test Acc:  0.771039\n",
            "Epoch: 218 | Time: 0m 12s\n",
            "\tTrain Loss: 0.501 | \t Train Acc:  0.849823\n",
            "\t Val. Loss: 0.540 | \t Valid Acc:  0.845510\n",
            "| Test Loss: 1.057 | \t Test Acc:  0.765796\n",
            "Epoch: 219 | Time: 0m 12s\n",
            "\tTrain Loss: 0.423 | \t Train Acc:  0.874205\n",
            "\t Val. Loss: 0.537 | \t Valid Acc:  0.847222\n",
            "| Test Loss: 1.042 | \t Test Acc:  0.768908\n",
            "Epoch: 220 | Time: 0m 12s\n",
            "\tTrain Loss: 0.408 | \t Train Acc:  0.879475\n",
            "\t Val. Loss: 0.518 | \t Valid Acc:  0.853781\n",
            "| Test Loss: 1.048 | \t Test Acc:  0.772121\n",
            "Epoch: 221 | Time: 0m 12s\n",
            "\tTrain Loss: 0.394 | \t Train Acc:  0.884220\n",
            "\t Val. Loss: 0.535 | \t Valid Acc:  0.845796\n",
            "| Test Loss: 1.105 | \t Test Acc:  0.765593\n",
            "Epoch: 222 | Time: 0m 12s\n",
            "\tTrain Loss: 0.474 | \t Train Acc:  0.862019\n",
            "\t Val. Loss: 0.515 | \t Valid Acc:  0.854257\n",
            "| Test Loss: 1.038 | \t Test Acc:  0.773711\n",
            "Epoch: 223 | Time: 0m 12s\n",
            "\tTrain Loss: 0.419 | \t Train Acc:  0.875134\n",
            "\t Val. Loss: 0.517 | \t Valid Acc:  0.853306\n",
            "| Test Loss: 1.045 | \t Test Acc:  0.774625\n",
            "Epoch: 224 | Time: 0m 12s\n",
            "\tTrain Loss: 0.424 | \t Train Acc:  0.872943\n",
            "\t Val. Loss: 0.511 | \t Valid Acc:  0.856063\n",
            "| Test Loss: 1.046 | \t Test Acc:  0.773644\n",
            "Epoch: 225 | Time: 0m 12s\n",
            "\tTrain Loss: 0.466 | \t Train Acc:  0.861575\n",
            "\t Val. Loss: 0.557 | \t Valid Acc:  0.838570\n",
            "| Test Loss: 1.055 | \t Test Acc:  0.762143\n",
            "Epoch: 226 | Time: 0m 12s\n",
            "\tTrain Loss: 0.405 | \t Train Acc:  0.880697\n",
            "\t Val. Loss: 0.593 | \t Valid Acc:  0.827019\n",
            "| Test Loss: 1.183 | \t Test Acc:  0.749357\n",
            "Epoch: 227 | Time: 0m 12s\n",
            "\tTrain Loss: 0.397 | \t Train Acc:  0.883311\n",
            "\t Val. Loss: 0.515 | \t Valid Acc:  0.852023\n",
            "| Test Loss: 1.044 | \t Test Acc:  0.769010\n",
            "Epoch: 228 | Time: 0m 12s\n",
            "\tTrain Loss: 0.448 | \t Train Acc:  0.865492\n",
            "\t Val. Loss: 0.528 | \t Valid Acc:  0.850454\n",
            "| Test Loss: 1.079 | \t Test Acc:  0.768840\n",
            "Epoch: 229 | Time: 0m 12s\n",
            "\tTrain Loss: 0.410 | \t Train Acc:  0.877769\n",
            "\t Val. Loss: 0.517 | \t Valid Acc:  0.852545\n",
            "| Test Loss: 1.080 | \t Test Acc:  0.771208\n",
            "Epoch: 230 | Time: 0m 12s\n",
            "\tTrain Loss: 0.396 | \t Train Acc:  0.883009\n",
            "\t Val. Loss: 0.579 | \t Valid Acc:  0.830014\n",
            "| Test Loss: 1.209 | \t Test Acc:  0.743167\n",
            "Epoch: 231 | Time: 0m 12s\n",
            "\tTrain Loss: 0.460 | \t Train Acc:  0.866078\n",
            "\t Val. Loss: 0.518 | \t Valid Acc:  0.851928\n",
            "| Test Loss: 1.041 | \t Test Acc:  0.770058\n",
            "Epoch: 232 | Time: 0m 12s\n",
            "\tTrain Loss: 0.383 | \t Train Acc:  0.888107\n",
            "\t Val. Loss: 0.528 | \t Valid Acc:  0.848743\n",
            "| Test Loss: 1.061 | \t Test Acc:  0.771276\n",
            "Epoch: 233 | Time: 0m 12s\n",
            "\tTrain Loss: 0.490 | \t Train Acc:  0.855972\n",
            "\t Val. Loss: 0.513 | \t Valid Acc:  0.854067\n",
            "| Test Loss: 1.043 | \t Test Acc:  0.770464\n",
            "Epoch: 234 | Time: 0m 12s\n",
            "\tTrain Loss: 0.395 | \t Train Acc:  0.883715\n",
            "\t Val. Loss: 0.512 | \t Valid Acc:  0.852260\n",
            "| Test Loss: 1.090 | \t Test Acc:  0.770566\n",
            "Epoch: 235 | Time: 0m 12s\n",
            "\tTrain Loss: 0.399 | \t Train Acc:  0.881807\n",
            "\t Val. Loss: 0.516 | \t Valid Acc:  0.850739\n",
            "| Test Loss: 1.050 | \t Test Acc:  0.767352\n",
            "Epoch: 236 | Time: 0m 12s\n",
            "\tTrain Loss: 0.381 | \t Train Acc:  0.888804\n",
            "\t Val. Loss: 0.491 | \t Valid Acc:  0.858392\n",
            "| Test Loss: 1.090 | \t Test Acc:  0.771310\n",
            "Epoch: 237 | Time: 0m 12s\n",
            "\tTrain Loss: 0.381 | \t Train Acc:  0.888269\n",
            "\t Val. Loss: 0.498 | \t Valid Acc:  0.857394\n",
            "| Test Loss: 1.091 | \t Test Acc:  0.772257\n",
            "Epoch: 238 | Time: 0m 12s\n",
            "\tTrain Loss: 0.534 | \t Train Acc:  0.849682\n",
            "\t Val. Loss: 0.501 | \t Valid Acc:  0.857394\n",
            "| Test Loss: 1.065 | \t Test Acc:  0.771377\n",
            "Epoch: 239 | Time: 0m 12s\n",
            "\tTrain Loss: 0.461 | \t Train Acc:  0.862181\n",
            "\t Val. Loss: 0.493 | \t Valid Acc:  0.859343\n",
            "| Test Loss: 1.055 | \t Test Acc:  0.772561\n",
            "Epoch: 240 | Time: 0m 12s\n",
            "\tTrain Loss: 0.390 | \t Train Acc:  0.884674\n",
            "\t Val. Loss: 0.493 | \t Valid Acc:  0.859296\n",
            "| Test Loss: 1.078 | \t Test Acc:  0.773576\n",
            "Epoch: 241 | Time: 0m 12s\n",
            "\tTrain Loss: 0.376 | \t Train Acc:  0.890126\n",
            "\t Val. Loss: 0.489 | \t Valid Acc:  0.859581\n",
            "| Test Loss: 1.056 | \t Test Acc:  0.776181\n",
            "Epoch: 242 | Time: 0m 12s\n",
            "\tTrain Loss: 0.408 | \t Train Acc:  0.879879\n",
            "\t Val. Loss: 0.691 | \t Valid Acc:  0.801540\n",
            "| Test Loss: 1.314 | \t Test Acc:  0.729401\n",
            "Epoch: 243 | Time: 0m 12s\n",
            "\tTrain Loss: 0.431 | \t Train Acc:  0.872973\n",
            "\t Val. Loss: 0.489 | \t Valid Acc:  0.860627\n",
            "| Test Loss: 1.045 | \t Test Acc:  0.773170\n",
            "Epoch: 244 | Time: 0m 12s\n",
            "\tTrain Loss: 0.375 | \t Train Acc:  0.890803\n",
            "\t Val. Loss: 0.502 | \t Valid Acc:  0.855208\n",
            "| Test Loss: 1.064 | \t Test Acc:  0.772595\n",
            "Epoch: 245 | Time: 0m 12s\n",
            "\tTrain Loss: 0.459 | \t Train Acc:  0.862786\n",
            "\t Val. Loss: 0.506 | \t Valid Acc:  0.855303\n",
            "| Test Loss: 1.051 | \t Test Acc:  0.772527\n",
            "Epoch: 246 | Time: 0m 12s\n",
            "\tTrain Loss: 0.389 | \t Train Acc:  0.884331\n",
            "\t Val. Loss: 0.497 | \t Valid Acc:  0.857679\n",
            "| Test Loss: 1.077 | \t Test Acc:  0.774523\n",
            "Epoch: 247 | Time: 0m 12s\n",
            "\tTrain Loss: 0.389 | \t Train Acc:  0.884664\n",
            "\t Val. Loss: 0.586 | \t Valid Acc:  0.828303\n",
            "| Test Loss: 1.105 | \t Test Acc:  0.753383\n",
            "Epoch: 248 | Time: 0m 12s\n",
            "\tTrain Loss: 0.435 | \t Train Acc:  0.871661\n",
            "\t Val. Loss: 0.484 | \t Valid Acc:  0.860912\n",
            "| Test Loss: 1.070 | \t Test Acc:  0.773644\n",
            "Epoch: 249 | Time: 0m 12s\n",
            "\tTrain Loss: 0.375 | \t Train Acc:  0.889753\n",
            "\t Val. Loss: 0.477 | \t Valid Acc:  0.863859\n",
            "| Test Loss: 1.080 | \t Test Acc:  0.773373\n",
            "Epoch: 250 | Time: 0m 12s\n",
            "\tTrain Loss: 0.383 | \t Train Acc:  0.886522\n",
            "\t Val. Loss: 0.492 | \t Valid Acc:  0.859486\n",
            "| Test Loss: 1.080 | \t Test Acc:  0.773745\n",
            "Epoch: 251 | Time: 0m 12s\n",
            "\tTrain Loss: 0.393 | \t Train Acc:  0.883443\n",
            "\t Val. Loss: 0.755 | \t Valid Acc:  0.785521\n",
            "| Test Loss: 1.456 | \t Test Acc:  0.698552\n",
            "Epoch: 252 | Time: 0m 12s\n",
            "\tTrain Loss: 0.457 | \t Train Acc:  0.869389\n",
            "\t Val. Loss: 0.509 | \t Valid Acc:  0.852736\n",
            "| Test Loss: 1.060 | \t Test Acc:  0.767724\n",
            "Epoch: 253 | Time: 0m 12s\n",
            "\tTrain Loss: 0.412 | \t Train Acc:  0.877325\n",
            "\t Val. Loss: 0.489 | \t Valid Acc:  0.859343\n",
            "| Test Loss: 1.059 | \t Test Acc:  0.774997\n",
            "Epoch: 254 | Time: 0m 12s\n",
            "\tTrain Loss: 0.369 | \t Train Acc:  0.891873\n",
            "\t Val. Loss: 0.475 | \t Valid Acc:  0.863336\n",
            "| Test Loss: 1.063 | \t Test Acc:  0.773069\n",
            "Epoch: 255 | Time: 0m 12s\n",
            "\tTrain Loss: 0.393 | \t Train Acc:  0.883180\n",
            "\t Val. Loss: 0.502 | \t Valid Acc:  0.854399\n",
            "| Test Loss: 1.074 | \t Test Acc:  0.771952\n",
            "Epoch: 256 | Time: 0m 12s\n",
            "\tTrain Loss: 0.473 | \t Train Acc:  0.861686\n",
            "\t Val. Loss: 0.504 | \t Valid Acc:  0.854352\n",
            "| Test Loss: 1.111 | \t Test Acc:  0.765864\n",
            "Epoch: 257 | Time: 0m 12s\n",
            "\tTrain Loss: 0.369 | \t Train Acc:  0.892489\n",
            "\t Val. Loss: 0.470 | \t Valid Acc:  0.864572\n",
            "| Test Loss: 1.058 | \t Test Acc:  0.776925\n",
            "Epoch: 258 | Time: 0m 12s\n",
            "\tTrain Loss: 0.366 | \t Train Acc:  0.893044\n",
            "\t Val. Loss: 0.489 | \t Valid Acc:  0.858392\n",
            "| Test Loss: 1.075 | \t Test Acc:  0.771513\n",
            "Epoch: 259 | Time: 0m 12s\n",
            "\tTrain Loss: 0.380 | \t Train Acc:  0.887875\n",
            "\t Val. Loss: 0.605 | \t Valid Acc:  0.820839\n",
            "| Test Loss: 1.302 | \t Test Acc:  0.733865\n",
            "Epoch: 260 | Time: 0m 12s\n",
            "\tTrain Loss: 0.440 | \t Train Acc:  0.875437\n",
            "\t Val. Loss: 0.481 | \t Valid Acc:  0.861387\n",
            "| Test Loss: 1.052 | \t Test Acc:  0.775030\n",
            "Epoch: 261 | Time: 0m 12s\n",
            "\tTrain Loss: 0.370 | \t Train Acc:  0.891146\n",
            "\t Val. Loss: 0.520 | \t Valid Acc:  0.847792\n",
            "| Test Loss: 1.077 | \t Test Acc:  0.767454\n",
            "Epoch: 262 | Time: 0m 12s\n",
            "\tTrain Loss: 0.369 | \t Train Acc:  0.891489\n",
            "\t Val. Loss: 0.476 | \t Valid Acc:  0.862671\n",
            "| Test Loss: 1.070 | \t Test Acc:  0.776654\n",
            "Epoch: 263 | Time: 0m 12s\n",
            "\tTrain Loss: 0.519 | \t Train Acc:  0.849854\n",
            "\t Val. Loss: 0.481 | \t Valid Acc:  0.862053\n",
            "| Test Loss: 1.093 | \t Test Acc:  0.767995\n",
            "Epoch: 264 | Time: 0m 12s\n",
            "\tTrain Loss: 0.391 | \t Train Acc:  0.884472\n",
            "\t Val. Loss: 0.464 | \t Valid Acc:  0.866236\n",
            "| Test Loss: 1.066 | \t Test Acc:  0.776417\n",
            "Epoch: 265 | Time: 0m 12s\n",
            "\tTrain Loss: 0.362 | \t Train Acc:  0.894589\n",
            "\t Val. Loss: 0.466 | \t Valid Acc:  0.865855\n",
            "| Test Loss: 1.095 | \t Test Acc:  0.774760\n",
            "Epoch: 266 | Time: 0m 12s\n",
            "\tTrain Loss: 0.358 | \t Train Acc:  0.895558\n",
            "\t Val. Loss: 0.444 | \t Valid Acc:  0.872273\n",
            "| Test Loss: 1.078 | \t Test Acc:  0.776756\n",
            "Epoch: 267 | Time: 0m 12s\n",
            "\tTrain Loss: 0.363 | \t Train Acc:  0.892761\n",
            "\t Val. Loss: 0.496 | \t Valid Acc:  0.856111\n",
            "| Test Loss: 1.089 | \t Test Acc:  0.772527\n",
            "Epoch: 268 | Time: 0m 12s\n",
            "\tTrain Loss: 0.506 | \t Train Acc:  0.853084\n",
            "\t Val. Loss: 0.477 | \t Valid Acc:  0.860912\n",
            "| Test Loss: 1.130 | \t Test Acc:  0.765729\n",
            "Epoch: 269 | Time: 0m 12s\n",
            "\tTrain Loss: 0.364 | \t Train Acc:  0.893700\n",
            "\t Val. Loss: 0.466 | \t Valid Acc:  0.865000\n",
            "| Test Loss: 1.073 | \t Test Acc:  0.776992\n",
            "Epoch: 270 | Time: 0m 12s\n",
            "\tTrain Loss: 0.361 | \t Train Acc:  0.894064\n",
            "\t Val. Loss: 0.465 | \t Valid Acc:  0.865142\n",
            "| Test Loss: 1.078 | \t Test Acc:  0.775233\n",
            "Epoch: 271 | Time: 0m 12s\n",
            "\tTrain Loss: 0.373 | \t Train Acc:  0.889490\n",
            "\t Val. Loss: 0.503 | \t Valid Acc:  0.853211\n",
            "| Test Loss: 1.088 | \t Test Acc:  0.770396\n",
            "Epoch: 272 | Time: 0m 12s\n",
            "\tTrain Loss: 0.431 | \t Train Acc:  0.874023\n",
            "\t Val. Loss: 0.568 | \t Valid Acc:  0.831535\n",
            "| Test Loss: 1.104 | \t Test Acc:  0.757611\n",
            "Epoch: 273 | Time: 0m 12s\n",
            "\tTrain Loss: 0.379 | \t Train Acc:  0.887441\n",
            "\t Val. Loss: 0.467 | \t Valid Acc:  0.862908\n",
            "| Test Loss: 1.142 | \t Test Acc:  0.765796\n",
            "Epoch: 274 | Time: 0m 12s\n",
            "\tTrain Loss: 0.358 | \t Train Acc:  0.894891\n",
            "\t Val. Loss: 0.454 | \t Valid Acc:  0.868755\n",
            "| Test Loss: 1.102 | \t Test Acc:  0.774997\n",
            "Epoch: 275 | Time: 0m 12s\n",
            "\tTrain Loss: 0.364 | \t Train Acc:  0.892670\n",
            "\t Val. Loss: 0.464 | \t Valid Acc:  0.865190\n",
            "| Test Loss: 1.152 | \t Test Acc:  0.768976\n",
            "Epoch: 276 | Time: 0m 12s\n",
            "\tTrain Loss: 0.532 | \t Train Acc:  0.847774\n",
            "\t Val. Loss: 0.464 | \t Valid Acc:  0.866188\n",
            "| Test Loss: 1.052 | \t Test Acc:  0.769652\n",
            "Epoch: 277 | Time: 0m 12s\n",
            "\tTrain Loss: 0.367 | \t Train Acc:  0.893014\n",
            "\t Val. Loss: 0.465 | \t Valid Acc:  0.865903\n",
            "| Test Loss: 1.097 | \t Test Acc:  0.775064\n",
            "Epoch: 278 | Time: 0m 12s\n",
            "\tTrain Loss: 0.356 | \t Train Acc:  0.895628\n",
            "\t Val. Loss: 0.448 | \t Valid Acc:  0.871037\n",
            "| Test Loss: 1.093 | \t Test Acc:  0.778413\n",
            "Epoch: 279 | Time: 0m 12s\n",
            "\tTrain Loss: 0.352 | \t Train Acc:  0.896729\n",
            "\t Val. Loss: 0.444 | \t Valid Acc:  0.871987\n",
            "| Test Loss: 1.082 | \t Test Acc:  0.777736\n",
            "Epoch: 280 | Time: 0m 12s\n",
            "\tTrain Loss: 0.463 | \t Train Acc:  0.867431\n",
            "\t Val. Loss: 0.461 | \t Valid Acc:  0.865095\n",
            "| Test Loss: 1.093 | \t Test Acc:  0.771783\n",
            "Epoch: 281 | Time: 0m 12s\n",
            "\tTrain Loss: 0.362 | \t Train Acc:  0.893872\n",
            "\t Val. Loss: 0.433 | \t Valid Acc:  0.873889\n",
            "| Test Loss: 1.075 | \t Test Acc:  0.777703\n",
            "Epoch: 282 | Time: 0m 12s\n",
            "\tTrain Loss: 0.354 | \t Train Acc:  0.896063\n",
            "\t Val. Loss: 0.445 | \t Valid Acc:  0.871084\n",
            "| Test Loss: 1.100 | \t Test Acc:  0.776958\n",
            "Epoch: 283 | Time: 0m 12s\n",
            "\tTrain Loss: 0.365 | \t Train Acc:  0.891217\n",
            "\t Val. Loss: 0.453 | \t Valid Acc:  0.868708\n",
            "| Test Loss: 1.120 | \t Test Acc:  0.775775\n",
            "Epoch: 284 | Time: 0m 12s\n",
            "\tTrain Loss: 0.443 | \t Train Acc:  0.873690\n",
            "\t Val. Loss: 0.476 | \t Valid Acc:  0.858820\n",
            "| Test Loss: 1.166 | \t Test Acc:  0.753856\n",
            "Epoch: 285 | Time: 0m 12s\n",
            "\tTrain Loss: 0.357 | \t Train Acc:  0.895639\n",
            "\t Val. Loss: 0.459 | \t Valid Acc:  0.865523\n",
            "| Test Loss: 1.090 | \t Test Acc:  0.772595\n",
            "Epoch: 286 | Time: 0m 12s\n",
            "\tTrain Loss: 0.349 | \t Train Acc:  0.897557\n",
            "\t Val. Loss: 0.458 | \t Valid Acc:  0.867377\n",
            "| Test Loss: 1.108 | \t Test Acc:  0.777398\n",
            "Epoch: 287 | Time: 0m 12s\n",
            "\tTrain Loss: 0.347 | \t Train Acc:  0.898253\n",
            "\t Val. Loss: 0.439 | \t Valid Acc:  0.872700\n",
            "| Test Loss: 1.112 | \t Test Acc:  0.777297\n",
            "Epoch: 288 | Time: 0m 12s\n",
            "\tTrain Loss: 0.517 | \t Train Acc:  0.854185\n",
            "\t Val. Loss: 0.470 | \t Valid Acc:  0.864810\n",
            "| Test Loss: 1.102 | \t Test Acc:  0.764680\n",
            "Epoch: 289 | Time: 0m 12s\n",
            "\tTrain Loss: 0.363 | \t Train Acc:  0.892832\n",
            "\t Val. Loss: 0.442 | \t Valid Acc:  0.871655\n",
            "| Test Loss: 1.102 | \t Test Acc:  0.776282\n",
            "Epoch: 290 | Time: 0m 12s\n",
            "\tTrain Loss: 0.352 | \t Train Acc:  0.896577\n",
            "\t Val. Loss: 0.441 | \t Valid Acc:  0.871465\n",
            "| Test Loss: 1.098 | \t Test Acc:  0.778379\n",
            "Epoch: 291 | Time: 0m 12s\n",
            "\tTrain Loss: 0.357 | \t Train Acc:  0.894498\n",
            "\t Val. Loss: 0.446 | \t Valid Acc:  0.870039\n",
            "| Test Loss: 1.106 | \t Test Acc:  0.777398\n",
            "Epoch: 292 | Time: 0m 12s\n",
            "\tTrain Loss: 0.343 | \t Train Acc:  0.899909\n",
            "\t Val. Loss: 0.432 | \t Valid Acc:  0.874554\n",
            "| Test Loss: 1.109 | \t Test Acc:  0.778109\n",
            "Epoch: 293 | Time: 0m 12s\n",
            "\tTrain Loss: 0.468 | \t Train Acc:  0.866330\n",
            "\t Val. Loss: 0.452 | \t Valid Acc:  0.868993\n",
            "| Test Loss: 1.107 | \t Test Acc:  0.770160\n",
            "Epoch: 294 | Time: 0m 12s\n",
            "\tTrain Loss: 0.400 | \t Train Acc:  0.881878\n",
            "\t Val. Loss: 0.436 | \t Valid Acc:  0.872653\n",
            "| Test Loss: 1.111 | \t Test Acc:  0.774997\n",
            "Epoch: 295 | Time: 0m 12s\n",
            "\tTrain Loss: 0.344 | \t Train Acc:  0.899960\n",
            "\t Val. Loss: 0.429 | \t Valid Acc:  0.875648\n",
            "| Test Loss: 1.116 | \t Test Acc:  0.776282\n",
            "Epoch: 296 | Time: 0m 12s\n",
            "\tTrain Loss: 0.341 | \t Train Acc:  0.900353\n",
            "\t Val. Loss: 0.429 | \t Valid Acc:  0.875077\n",
            "| Test Loss: 1.112 | \t Test Acc:  0.777297\n",
            "Epoch: 297 | Time: 0m 12s\n",
            "\tTrain Loss: 0.467 | \t Train Acc:  0.866411\n",
            "\t Val. Loss: 0.442 | \t Valid Acc:  0.870989\n",
            "| Test Loss: 1.100 | \t Test Acc:  0.770193\n",
            "Epoch: 298 | Time: 0m 12s\n",
            "\tTrain Loss: 0.348 | \t Train Acc:  0.898375\n",
            "\t Val. Loss: 0.429 | \t Valid Acc:  0.874982\n",
            "| Test Loss: 1.121 | \t Test Acc:  0.774625\n",
            "Epoch: 299 | Time: 0m 12s\n",
            "\tTrain Loss: 0.342 | \t Train Acc:  0.899344\n",
            "\t Val. Loss: 0.426 | \t Valid Acc:  0.875505\n",
            "| Test Loss: 1.104 | \t Test Acc:  0.778345\n",
            "Epoch: 300 | Time: 0m 12s\n",
            "\tTrain Loss: 0.343 | \t Train Acc:  0.899455\n",
            "\t Val. Loss: 0.429 | \t Valid Acc:  0.874127\n",
            "| Test Loss: 1.103 | \t Test Acc:  0.778582\n",
            "Epoch: 301 | Time: 0m 12s\n",
            "\tTrain Loss: 0.339 | \t Train Acc:  0.900586\n",
            "\t Val. Loss: 0.419 | \t Valid Acc:  0.877787\n",
            "| Test Loss: 1.129 | \t Test Acc:  0.777500\n",
            "Epoch: 302 | Time: 0m 12s\n",
            "\tTrain Loss: 0.453 | \t Train Acc:  0.869096\n",
            "\t Val. Loss: 0.439 | \t Valid Acc:  0.871940\n",
            "| Test Loss: 1.138 | \t Test Acc:  0.770599\n",
            "Epoch: 303 | Time: 0m 12s\n",
            "\tTrain Loss: 0.363 | \t Train Acc:  0.891984\n",
            "\t Val. Loss: 0.438 | \t Valid Acc:  0.871845\n",
            "| Test Loss: 1.094 | \t Test Acc:  0.778075\n",
            "Epoch: 304 | Time: 0m 12s\n",
            "\tTrain Loss: 0.340 | \t Train Acc:  0.900384\n",
            "\t Val. Loss: 0.423 | \t Valid Acc:  0.876218\n",
            "| Test Loss: 1.099 | \t Test Acc:  0.778650\n",
            "Epoch: 305 | Time: 0m 12s\n",
            "\tTrain Loss: 0.337 | \t Train Acc:  0.901333\n",
            "\t Val. Loss: 0.430 | \t Valid Acc:  0.874222\n",
            "| Test Loss: 1.137 | \t Test Acc:  0.777466\n",
            "Epoch: 306 | Time: 0m 12s\n",
            "\tTrain Loss: 0.458 | \t Train Acc:  0.868158\n",
            "\t Val. Loss: 0.427 | \t Valid Acc:  0.874697\n",
            "| Test Loss: 1.092 | \t Test Acc:  0.772629\n",
            "Epoch: 307 | Time: 0m 12s\n",
            "\tTrain Loss: 0.360 | \t Train Acc:  0.894114\n",
            "\t Val. Loss: 0.436 | \t Valid Acc:  0.871512\n",
            "| Test Loss: 1.117 | \t Test Acc:  0.777026\n",
            "Epoch: 308 | Time: 0m 12s\n",
            "\tTrain Loss: 0.342 | \t Train Acc:  0.899566\n",
            "\t Val. Loss: 0.422 | \t Valid Acc:  0.875410\n",
            "| Test Loss: 1.103 | \t Test Acc:  0.778616\n",
            "Epoch: 309 | Time: 0m 12s\n",
            "\tTrain Loss: 0.337 | \t Train Acc:  0.900959\n",
            "\t Val. Loss: 0.415 | \t Valid Acc:  0.878262\n",
            "| Test Loss: 1.123 | \t Test Acc:  0.777500\n",
            "Epoch: 310 | Time: 0m 12s\n",
            "\tTrain Loss: 0.349 | \t Train Acc:  0.896436\n",
            "\t Val. Loss: 1.176 | \t Valid Acc:  0.716024\n",
            "| Test Loss: 1.479 | \t Test Acc:  0.685564\n",
            "Epoch: 311 | Time: 0m 12s\n",
            "\tTrain Loss: 0.416 | \t Train Acc:  0.881454\n",
            "\t Val. Loss: 0.497 | \t Valid Acc:  0.852355\n",
            "| Test Loss: 1.247 | \t Test Acc:  0.756258\n",
            "Epoch: 312 | Time: 0m 12s\n",
            "\tTrain Loss: 0.338 | \t Train Acc:  0.900777\n",
            "\t Val. Loss: 0.427 | \t Valid Acc:  0.875458\n",
            "| Test Loss: 1.120 | \t Test Acc:  0.780307\n",
            "Epoch: 313 | Time: 0m 12s\n",
            "\tTrain Loss: 0.355 | \t Train Acc:  0.894851\n",
            "\t Val. Loss: 0.414 | \t Valid Acc:  0.877787\n",
            "| Test Loss: 1.132 | \t Test Acc:  0.775538\n",
            "Epoch: 314 | Time: 0m 12s\n",
            "\tTrain Loss: 0.399 | \t Train Acc:  0.881373\n",
            "\t Val. Loss: 0.420 | \t Valid Acc:  0.877121\n",
            "| Test Loss: 1.107 | \t Test Acc:  0.777872\n",
            "Epoch: 315 | Time: 0m 12s\n",
            "\tTrain Loss: 0.336 | \t Train Acc:  0.901504\n",
            "\t Val. Loss: 0.417 | \t Valid Acc:  0.877359\n",
            "| Test Loss: 1.132 | \t Test Acc:  0.778311\n",
            "Epoch: 316 | Time: 0m 12s\n",
            "\tTrain Loss: 0.338 | \t Train Acc:  0.900626\n",
            "\t Val. Loss: 0.412 | \t Valid Acc:  0.879546\n",
            "| Test Loss: 1.140 | \t Test Acc:  0.778142\n",
            "Epoch: 317 | Time: 0m 12s\n",
            "\tTrain Loss: 0.381 | \t Train Acc:  0.887764\n",
            "\t Val. Loss: 1.092 | \t Valid Acc:  0.717878\n",
            "| Test Loss: 1.465 | \t Test Acc:  0.677615\n",
            "Epoch: 318 | Time: 0m 12s\n",
            "\tTrain Loss: 0.385 | \t Train Acc:  0.887198\n",
            "\t Val. Loss: 0.456 | \t Valid Acc:  0.866046\n",
            "| Test Loss: 1.201 | \t Test Acc:  0.766710\n",
            "Epoch: 319 | Time: 0m 12s\n",
            "\tTrain Loss: 0.335 | \t Train Acc:  0.901686\n",
            "\t Val. Loss: 0.416 | \t Valid Acc:  0.877977\n",
            "| Test Loss: 1.145 | \t Test Acc:  0.777567\n",
            "Epoch: 320 | Time: 0m 12s\n",
            "\tTrain Loss: 0.337 | \t Train Acc:  0.900697\n",
            "\t Val. Loss: 0.418 | \t Valid Acc:  0.876836\n",
            "| Test Loss: 1.169 | \t Test Acc:  0.772764\n",
            "Epoch: 321 | Time: 0m 12s\n",
            "\tTrain Loss: 0.334 | \t Train Acc:  0.901858\n",
            "\t Val. Loss: 0.418 | \t Valid Acc:  0.877264\n",
            "| Test Loss: 1.122 | \t Test Acc:  0.779563\n",
            "Epoch: 322 | Time: 0m 12s\n",
            "\tTrain Loss: 0.486 | \t Train Acc:  0.863624\n",
            "\t Val. Loss: 0.433 | \t Valid Acc:  0.872796\n",
            "| Test Loss: 1.152 | \t Test Acc:  0.768502\n",
            "Epoch: 323 | Time: 0m 12s\n",
            "\tTrain Loss: 0.363 | \t Train Acc:  0.892569\n",
            "\t Val. Loss: 0.408 | \t Valid Acc:  0.879831\n",
            "| Test Loss: 1.110 | \t Test Acc:  0.778650\n",
            "Epoch: 324 | Time: 0m 12s\n",
            "\tTrain Loss: 0.332 | \t Train Acc:  0.902958\n",
            "\t Val. Loss: 0.409 | \t Valid Acc:  0.879783\n",
            "| Test Loss: 1.122 | \t Test Acc:  0.780239\n",
            "Epoch: 325 | Time: 0m 12s\n",
            "\tTrain Loss: 0.329 | \t Train Acc:  0.903069\n",
            "\t Val. Loss: 0.408 | \t Valid Acc:  0.880591\n",
            "| Test Loss: 1.142 | \t Test Acc:  0.778447\n",
            "Epoch: 326 | Time: 0m 12s\n",
            "\tTrain Loss: 0.325 | \t Train Acc:  0.904907\n",
            "\t Val. Loss: 0.403 | \t Valid Acc:  0.881637\n",
            "| Test Loss: 1.131 | \t Test Acc:  0.781187\n",
            "Epoch: 327 | Time: 0m 12s\n",
            "\tTrain Loss: 0.525 | \t Train Acc:  0.854508\n",
            "\t Val. Loss: 0.429 | \t Valid Acc:  0.873936\n",
            "| Test Loss: 1.125 | \t Test Acc:  0.766168\n",
            "Epoch: 328 | Time: 0m 12s\n",
            "\tTrain Loss: 0.349 | \t Train Acc:  0.897486\n",
            "\t Val. Loss: 0.410 | \t Valid Acc:  0.879688\n",
            "| Test Loss: 1.120 | \t Test Acc:  0.778548\n",
            "Epoch: 329 | Time: 0m 12s\n",
            "\tTrain Loss: 0.330 | \t Train Acc:  0.903433\n",
            "\t Val. Loss: 0.400 | \t Valid Acc:  0.882730\n",
            "| Test Loss: 1.127 | \t Test Acc:  0.779056\n",
            "Epoch: 330 | Time: 0m 12s\n",
            "\tTrain Loss: 0.329 | \t Train Acc:  0.903493\n",
            "\t Val. Loss: 0.407 | \t Valid Acc:  0.880496\n",
            "| Test Loss: 1.135 | \t Test Acc:  0.779901\n",
            "Epoch: 331 | Time: 0m 12s\n",
            "\tTrain Loss: 0.434 | \t Train Acc:  0.876123\n",
            "\t Val. Loss: 0.414 | \t Valid Acc:  0.877454\n",
            "| Test Loss: 1.121 | \t Test Acc:  0.770701\n",
            "Epoch: 332 | Time: 0m 12s\n",
            "\tTrain Loss: 0.336 | \t Train Acc:  0.901636\n",
            "\t Val. Loss: 0.414 | \t Valid Acc:  0.878167\n",
            "| Test Loss: 1.152 | \t Test Acc:  0.776925\n",
            "Epoch: 333 | Time: 0m 12s\n",
            "\tTrain Loss: 0.329 | \t Train Acc:  0.903423\n",
            "\t Val. Loss: 0.404 | \t Valid Acc:  0.880829\n",
            "| Test Loss: 1.119 | \t Test Acc:  0.779901\n",
            "Epoch: 334 | Time: 0m 12s\n",
            "\tTrain Loss: 0.330 | \t Train Acc:  0.903029\n",
            "\t Val. Loss: 0.401 | \t Valid Acc:  0.881399\n",
            "| Test Loss: 1.131 | \t Test Acc:  0.780341\n",
            "Epoch: 335 | Time: 0m 12s\n",
            "\tTrain Loss: 0.324 | \t Train Acc:  0.905018\n",
            "\t Val. Loss: 0.402 | \t Valid Acc:  0.881162\n",
            "| Test Loss: 1.154 | \t Test Acc:  0.780307\n",
            "Epoch: 336 | Time: 0m 12s\n",
            "\tTrain Loss: 0.330 | \t Train Acc:  0.902645\n",
            "\t Val. Loss: 0.414 | \t Valid Acc:  0.878120\n",
            "| Test Loss: 1.190 | \t Test Acc:  0.776079\n",
            "Epoch: 337 | Time: 0m 12s\n",
            "\tTrain Loss: 0.325 | \t Train Acc:  0.904250\n",
            "\t Val. Loss: 0.393 | \t Valid Acc:  0.884537\n",
            "| Test Loss: 1.172 | \t Test Acc:  0.777128\n",
            "Epoch: 338 | Time: 0m 12s\n",
            "\tTrain Loss: 0.452 | \t Train Acc:  0.878233\n",
            "\t Val. Loss: 0.407 | \t Valid Acc:  0.878880\n",
            "| Test Loss: 1.121 | \t Test Acc:  0.778176\n",
            "Epoch: 339 | Time: 0m 12s\n",
            "\tTrain Loss: 0.344 | \t Train Acc:  0.898082\n",
            "\t Val. Loss: 0.393 | \t Valid Acc:  0.883586\n",
            "| Test Loss: 1.119 | \t Test Acc:  0.780747\n",
            "Epoch: 340 | Time: 0m 12s\n",
            "\tTrain Loss: 0.369 | \t Train Acc:  0.891630\n",
            "\t Val. Loss: 0.433 | \t Valid Acc:  0.870134\n",
            "| Test Loss: 1.195 | \t Test Acc:  0.765864\n",
            "Epoch: 341 | Time: 0m 12s\n",
            "\tTrain Loss: 0.330 | \t Train Acc:  0.903110\n",
            "\t Val. Loss: 0.421 | \t Valid Acc:  0.875505\n",
            "| Test Loss: 1.130 | \t Test Acc:  0.771919\n",
            "Epoch: 342 | Time: 0m 12s\n",
            "\tTrain Loss: 0.323 | \t Train Acc:  0.905432\n",
            "\t Val. Loss: 0.383 | \t Valid Acc:  0.887532\n",
            "| Test Loss: 1.133 | \t Test Acc:  0.781491\n",
            "Epoch: 343 | Time: 0m 12s\n",
            "\tTrain Loss: 0.322 | \t Train Acc:  0.905684\n",
            "\t Val. Loss: 0.389 | \t Valid Acc:  0.885107\n",
            "| Test Loss: 1.143 | \t Test Acc:  0.781356\n",
            "Epoch: 344 | Time: 0m 12s\n",
            "\tTrain Loss: 0.514 | \t Train Acc:  0.860626\n",
            "\t Val. Loss: 0.424 | \t Valid Acc:  0.876456\n",
            "| Test Loss: 1.139 | \t Test Acc:  0.772054\n",
            "Epoch: 345 | Time: 0m 12s\n",
            "\tTrain Loss: 0.427 | \t Train Acc:  0.879293\n",
            "\t Val. Loss: 0.404 | \t Valid Acc:  0.881209\n",
            "| Test Loss: 1.157 | \t Test Acc:  0.774523\n",
            "Epoch: 346 | Time: 0m 12s\n",
            "\tTrain Loss: 0.325 | \t Train Acc:  0.905058\n",
            "\t Val. Loss: 0.391 | \t Valid Acc:  0.884537\n",
            "| Test Loss: 1.124 | \t Test Acc:  0.781559\n",
            "Epoch: 347 | Time: 0m 12s\n",
            "\tTrain Loss: 0.324 | \t Train Acc:  0.904987\n",
            "\t Val. Loss: 0.390 | \t Valid Acc:  0.884822\n",
            "| Test Loss: 1.146 | \t Test Acc:  0.780206\n",
            "Epoch: 348 | Time: 0m 12s\n",
            "\tTrain Loss: 0.322 | \t Train Acc:  0.905593\n",
            "\t Val. Loss: 0.401 | \t Valid Acc:  0.881209\n",
            "| Test Loss: 1.138 | \t Test Acc:  0.778717\n",
            "Epoch: 349 | Time: 0m 12s\n",
            "\tTrain Loss: 0.397 | \t Train Acc:  0.883422\n",
            "\t Val. Loss: 0.410 | \t Valid Acc:  0.878072\n",
            "| Test Loss: 1.177 | \t Test Acc:  0.773711\n",
            "Epoch: 350 | Time: 0m 12s\n",
            "\tTrain Loss: 0.331 | \t Train Acc:  0.902484\n",
            "\t Val. Loss: 0.395 | \t Valid Acc:  0.883348\n",
            "| Test Loss: 1.138 | \t Test Acc:  0.781423\n",
            "Epoch: 351 | Time: 0m 12s\n",
            "\tTrain Loss: 0.320 | \t Train Acc:  0.906148\n",
            "\t Val. Loss: 0.391 | \t Valid Acc:  0.884822\n",
            "| Test Loss: 1.137 | \t Test Acc:  0.780578\n",
            "Epoch: 352 | Time: 0m 12s\n",
            "\tTrain Loss: 0.320 | \t Train Acc:  0.905745\n",
            "\t Val. Loss: 0.387 | \t Valid Acc:  0.885820\n",
            "| Test Loss: 1.160 | \t Test Acc:  0.781525\n",
            "Epoch: 353 | Time: 0m 12s\n",
            "\tTrain Loss: 0.383 | \t Train Acc:  0.885533\n",
            "\t Val. Loss: 0.420 | \t Valid Acc:  0.875790\n",
            "| Test Loss: 1.224 | \t Test Acc:  0.769077\n",
            "Epoch: 354 | Time: 0m 12s\n",
            "\tTrain Loss: 0.399 | \t Train Acc:  0.884634\n",
            "\t Val. Loss: 0.399 | \t Valid Acc:  0.883491\n",
            "| Test Loss: 1.121 | \t Test Acc:  0.781356\n",
            "Epoch: 355 | Time: 0m 12s\n",
            "\tTrain Loss: 0.320 | \t Train Acc:  0.906159\n",
            "\t Val. Loss: 0.386 | \t Valid Acc:  0.886676\n",
            "| Test Loss: 1.129 | \t Test Acc:  0.781897\n",
            "Epoch: 356 | Time: 0m 12s\n",
            "\tTrain Loss: 0.320 | \t Train Acc:  0.906138\n",
            "\t Val. Loss: 0.388 | \t Valid Acc:  0.886343\n",
            "| Test Loss: 1.137 | \t Test Acc:  0.782912\n",
            "Epoch: 357 | Time: 0m 12s\n",
            "\tTrain Loss: 0.326 | \t Train Acc:  0.903806\n",
            "\t Val. Loss: 0.381 | \t Valid Acc:  0.887627\n",
            "| Test Loss: 1.159 | \t Test Acc:  0.780442\n",
            "Epoch: 358 | Time: 0m 12s\n",
            "\tTrain Loss: 0.325 | \t Train Acc:  0.903675\n",
            "\t Val. Loss: 0.386 | \t Valid Acc:  0.887151\n",
            "| Test Loss: 1.149 | \t Test Acc:  0.780781\n",
            "Epoch: 359 | Time: 0m 12s\n",
            "\tTrain Loss: 0.438 | \t Train Acc:  0.873347\n",
            "\t Val. Loss: 0.431 | \t Valid Acc:  0.872986\n",
            "| Test Loss: 1.132 | \t Test Acc:  0.772054\n",
            "Epoch: 360 | Time: 0m 12s\n",
            "\tTrain Loss: 0.328 | \t Train Acc:  0.903816\n",
            "\t Val. Loss: 0.388 | \t Valid Acc:  0.885583\n",
            "| Test Loss: 1.168 | \t Test Acc:  0.778244\n",
            "Epoch: 361 | Time: 0m 12s\n",
            "\tTrain Loss: 0.320 | \t Train Acc:  0.905967\n",
            "\t Val. Loss: 0.385 | \t Valid Acc:  0.886866\n",
            "| Test Loss: 1.150 | \t Test Acc:  0.780713\n",
            "Epoch: 362 | Time: 0m 12s\n",
            "\tTrain Loss: 0.318 | \t Train Acc:  0.906360\n",
            "\t Val. Loss: 0.375 | \t Valid Acc:  0.888910\n",
            "| Test Loss: 1.154 | \t Test Acc:  0.783318\n",
            "Epoch: 363 | Time: 0m 12s\n",
            "\tTrain Loss: 0.319 | \t Train Acc:  0.905856\n",
            "\t Val. Loss: 0.397 | \t Valid Acc:  0.882825\n",
            "| Test Loss: 1.185 | \t Test Acc:  0.782303\n",
            "Epoch: 364 | Time: 0m 12s\n",
            "\tTrain Loss: 0.419 | \t Train Acc:  0.879818\n",
            "\t Val. Loss: 0.388 | \t Valid Acc:  0.885297\n",
            "| Test Loss: 1.129 | \t Test Acc:  0.779089\n",
            "Epoch: 365 | Time: 0m 12s\n",
            "\tTrain Loss: 0.321 | \t Train Acc:  0.905835\n",
            "\t Val. Loss: 0.375 | \t Valid Acc:  0.888435\n",
            "| Test Loss: 1.155 | \t Test Acc:  0.782066\n",
            "Epoch: 366 | Time: 0m 12s\n",
            "\tTrain Loss: 0.324 | \t Train Acc:  0.904624\n",
            "\t Val. Loss: 0.396 | \t Valid Acc:  0.882445\n",
            "| Test Loss: 1.217 | \t Test Acc:  0.774929\n",
            "Epoch: 367 | Time: 0m 12s\n",
            "\tTrain Loss: 0.318 | \t Train Acc:  0.906310\n",
            "\t Val. Loss: 0.454 | \t Valid Acc:  0.867472\n",
            "| Test Loss: 1.201 | \t Test Acc:  0.764883\n",
            "Epoch: 368 | Time: 0m 12s\n",
            "\tTrain Loss: 0.406 | \t Train Acc:  0.885422\n",
            "\t Val. Loss: 0.380 | \t Valid Acc:  0.887674\n",
            "| Test Loss: 1.157 | \t Test Acc:  0.780916\n",
            "Epoch: 369 | Time: 0m 12s\n",
            "\tTrain Loss: 0.314 | \t Train Acc:  0.907643\n",
            "\t Val. Loss: 0.388 | \t Valid Acc:  0.885583\n",
            "| Test Loss: 1.162 | \t Test Acc:  0.781288\n",
            "Epoch: 370 | Time: 0m 12s\n",
            "\tTrain Loss: 0.328 | \t Train Acc:  0.902534\n",
            "\t Val. Loss: 0.387 | \t Valid Acc:  0.885535\n",
            "| Test Loss: 1.193 | \t Test Acc:  0.778920\n",
            "Epoch: 371 | Time: 0m 12s\n",
            "\tTrain Loss: 0.345 | \t Train Acc:  0.896870\n",
            "\t Val. Loss: 0.382 | \t Valid Acc:  0.887389\n",
            "| Test Loss: 1.172 | \t Test Acc:  0.779123\n",
            "Epoch: 372 | Time: 0m 12s\n",
            "\tTrain Loss: 0.318 | \t Train Acc:  0.906088\n",
            "\t Val. Loss: 0.382 | \t Valid Acc:  0.887389\n",
            "| Test Loss: 1.168 | \t Test Acc:  0.782506\n",
            "Epoch: 373 | Time: 0m 12s\n",
            "\tTrain Loss: 0.316 | \t Train Acc:  0.906684\n",
            "\t Val. Loss: 0.375 | \t Valid Acc:  0.890003\n",
            "| Test Loss: 1.170 | \t Test Acc:  0.780848\n",
            "Epoch: 374 | Time: 0m 12s\n",
            "\tTrain Loss: 0.322 | \t Train Acc:  0.904664\n",
            "\t Val. Loss: 0.372 | \t Valid Acc:  0.890003\n",
            "| Test Loss: 1.188 | \t Test Acc:  0.780442\n",
            "Epoch: 375 | Time: 0m 12s\n",
            "\tTrain Loss: 0.313 | \t Train Acc:  0.907299\n",
            "\t Val. Loss: 0.460 | \t Valid Acc:  0.865237\n",
            "| Test Loss: 1.204 | \t Test Acc:  0.767048\n",
            "Epoch: 376 | Time: 0m 12s\n",
            "\tTrain Loss: 0.431 | \t Train Acc:  0.881000\n",
            "\t Val. Loss: 0.372 | \t Valid Acc:  0.890384\n",
            "| Test Loss: 1.158 | \t Test Acc:  0.781863\n",
            "Epoch: 377 | Time: 0m 12s\n",
            "\tTrain Loss: 0.316 | \t Train Acc:  0.906714\n",
            "\t Val. Loss: 0.377 | \t Valid Acc:  0.888530\n",
            "| Test Loss: 1.181 | \t Test Acc:  0.782100\n",
            "Epoch: 378 | Time: 0m 12s\n",
            "\tTrain Loss: 0.313 | \t Train Acc:  0.907602\n",
            "\t Val. Loss: 0.379 | \t Valid Acc:  0.887959\n",
            "| Test Loss: 1.180 | \t Test Acc:  0.782100\n",
            "Epoch: 379 | Time: 0m 12s\n",
            "\tTrain Loss: 0.310 | \t Train Acc:  0.908400\n",
            "\t Val. Loss: 0.369 | \t Valid Acc:  0.891667\n",
            "| Test Loss: 1.162 | \t Test Acc:  0.781998\n",
            "Epoch: 380 | Time: 0m 12s\n",
            "\tTrain Loss: 0.448 | \t Train Acc:  0.875679\n",
            "\t Val. Loss: 0.386 | \t Valid Acc:  0.885820\n",
            "| Test Loss: 1.186 | \t Test Acc:  0.773339\n",
            "Epoch: 381 | Time: 0m 12s\n",
            "\tTrain Loss: 0.324 | \t Train Acc:  0.904654\n",
            "\t Val. Loss: 0.385 | \t Valid Acc:  0.886296\n",
            "| Test Loss: 1.180 | \t Test Acc:  0.779867\n",
            "Epoch: 382 | Time: 0m 12s\n",
            "\tTrain Loss: 0.312 | \t Train Acc:  0.907764\n",
            "\t Val. Loss: 0.370 | \t Valid Acc:  0.891097\n",
            "| Test Loss: 1.185 | \t Test Acc:  0.780172\n",
            "Epoch: 383 | Time: 0m 12s\n",
            "\tTrain Loss: 0.315 | \t Train Acc:  0.906704\n",
            "\t Val. Loss: 0.381 | \t Valid Acc:  0.887199\n",
            "| Test Loss: 1.169 | \t Test Acc:  0.778413\n",
            "Epoch: 384 | Time: 0m 12s\n",
            "\tTrain Loss: 0.312 | \t Train Acc:  0.908026\n",
            "\t Val. Loss: 0.378 | \t Valid Acc:  0.888577\n",
            "| Test Loss: 1.189 | \t Test Acc:  0.781288\n",
            "Epoch: 385 | Time: 0m 12s\n",
            "\tTrain Loss: 0.451 | \t Train Acc:  0.871206\n",
            "\t Val. Loss: 0.377 | \t Valid Acc:  0.888958\n",
            "| Test Loss: 1.134 | \t Test Acc:  0.779969\n",
            "Epoch: 386 | Time: 0m 12s\n",
            "\tTrain Loss: 0.317 | \t Train Acc:  0.907198\n",
            "\t Val. Loss: 0.378 | \t Valid Acc:  0.888149\n",
            "| Test Loss: 1.171 | \t Test Acc:  0.780273\n",
            "Epoch: 387 | Time: 0m 12s\n",
            "\tTrain Loss: 0.312 | \t Train Acc:  0.908168\n",
            "\t Val. Loss: 0.368 | \t Valid Acc:  0.891334\n",
            "| Test Loss: 1.173 | \t Test Acc:  0.782066\n",
            "Epoch: 388 | Time: 0m 12s\n",
            "\tTrain Loss: 0.310 | \t Train Acc:  0.908642\n",
            "\t Val. Loss: 0.360 | \t Valid Acc:  0.893996\n",
            "| Test Loss: 1.182 | \t Test Acc:  0.781965\n",
            "Epoch: 389 | Time: 0m 12s\n",
            "\tTrain Loss: 0.308 | \t Train Acc:  0.909642\n",
            "\t Val. Loss: 0.371 | \t Valid Acc:  0.890241\n",
            "| Test Loss: 1.187 | \t Test Acc:  0.782540\n",
            "Epoch: 390 | Time: 0m 12s\n",
            "\tTrain Loss: 0.466 | \t Train Acc:  0.872267\n",
            "\t Val. Loss: 0.385 | \t Valid Acc:  0.886866\n",
            "| Test Loss: 1.130 | \t Test Acc:  0.773948\n",
            "Epoch: 391 | Time: 0m 12s\n",
            "\tTrain Loss: 0.324 | \t Train Acc:  0.904866\n",
            "\t Val. Loss: 0.365 | \t Valid Acc:  0.892047\n",
            "| Test Loss: 1.154 | \t Test Acc:  0.782066\n",
            "Epoch: 392 | Time: 0m 12s\n",
            "\tTrain Loss: 0.310 | \t Train Acc:  0.909147\n",
            "\t Val. Loss: 0.361 | \t Valid Acc:  0.892951\n",
            "| Test Loss: 1.168 | \t Test Acc:  0.783791\n",
            "Epoch: 393 | Time: 0m 12s\n",
            "\tTrain Loss: 0.310 | \t Train Acc:  0.908662\n",
            "\t Val. Loss: 0.380 | \t Valid Acc:  0.886914\n",
            "| Test Loss: 1.221 | \t Test Acc:  0.780003\n",
            "Epoch: 394 | Time: 0m 12s\n",
            "\tTrain Loss: 0.309 | \t Train Acc:  0.908794\n",
            "\t Val. Loss: 0.360 | \t Valid Acc:  0.893568\n",
            "| Test Loss: 1.182 | \t Test Acc:  0.782776\n",
            "Epoch: 395 | Time: 0m 12s\n",
            "\tTrain Loss: 0.349 | \t Train Acc:  0.895790\n",
            "\t Val. Loss: 0.372 | \t Valid Acc:  0.890098\n",
            "| Test Loss: 1.180 | \t Test Acc:  0.781491\n",
            "Epoch: 396 | Time: 0m 12s\n",
            "\tTrain Loss: 0.307 | \t Train Acc:  0.909985\n",
            "\t Val. Loss: 0.386 | \t Valid Acc:  0.885963\n",
            "| Test Loss: 1.193 | \t Test Acc:  0.774252\n",
            "Epoch: 397 | Time: 0m 12s\n",
            "\tTrain Loss: 0.446 | \t Train Acc:  0.878920\n",
            "\t Val. Loss: 0.384 | \t Valid Acc:  0.885630\n",
            "| Test Loss: 1.168 | \t Test Acc:  0.771648\n",
            "Epoch: 398 | Time: 0m 12s\n",
            "\tTrain Loss: 0.318 | \t Train Acc:  0.906461\n",
            "\t Val. Loss: 0.369 | \t Valid Acc:  0.891002\n",
            "| Test Loss: 1.199 | \t Test Acc:  0.778109\n",
            "Epoch: 399 | Time: 0m 12s\n",
            "\tTrain Loss: 0.307 | \t Train Acc:  0.909672\n",
            "\t Val. Loss: 0.369 | \t Valid Acc:  0.890384\n",
            "| Test Loss: 1.183 | \t Test Acc:  0.781051\n",
            "Epoch: 400 | Time: 0m 12s\n",
            "\tTrain Loss: 0.308 | \t Train Acc:  0.909561\n",
            "\t Val. Loss: 0.359 | \t Valid Acc:  0.893093\n",
            "| Test Loss: 1.194 | \t Test Acc:  0.780747\n",
            "Epoch: 401 | Time: 0m 12s\n",
            "\tTrain Loss: 0.309 | \t Train Acc:  0.908935\n",
            "\t Val. Loss: 0.363 | \t Valid Acc:  0.892760\n",
            "| Test Loss: 1.173 | \t Test Acc:  0.779428\n",
            "Epoch: 402 | Time: 0m 12s\n",
            "\tTrain Loss: 0.349 | \t Train Acc:  0.898274\n",
            "\t Val. Loss: 1.780 | \t Valid Acc:  0.625089\n",
            "| Test Loss: 2.071 | \t Test Acc:  0.612197\n",
            "Epoch: 403 | Time: 0m 12s\n",
            "\tTrain Loss: 0.379 | \t Train Acc:  0.890803\n",
            "\t Val. Loss: 0.448 | \t Valid Acc:  0.868470\n",
            "| Test Loss: 1.326 | \t Test Acc:  0.754127\n",
            "Epoch: 404 | Time: 0m 12s\n",
            "\tTrain Loss: 0.311 | \t Train Acc:  0.908521\n",
            "\t Val. Loss: 0.366 | \t Valid Acc:  0.891144\n",
            "| Test Loss: 1.216 | \t Test Acc:  0.776857\n",
            "Epoch: 405 | Time: 0m 12s\n",
            "\tTrain Loss: 0.307 | \t Train Acc:  0.909510\n",
            "\t Val. Loss: 0.358 | \t Valid Acc:  0.893616\n",
            "| Test Loss: 1.213 | \t Test Acc:  0.778244\n",
            "Epoch: 406 | Time: 0m 12s\n",
            "\tTrain Loss: 0.310 | \t Train Acc:  0.908349\n",
            "\t Val. Loss: 0.372 | \t Valid Acc:  0.889005\n",
            "| Test Loss: 1.202 | \t Test Acc:  0.781153\n",
            "Epoch: 407 | Time: 0m 12s\n",
            "\tTrain Loss: 0.304 | \t Train Acc:  0.910268\n",
            "\t Val. Loss: 0.367 | \t Valid Acc:  0.890716\n",
            "| Test Loss: 1.265 | \t Test Acc:  0.772527\n",
            "Epoch: 408 | Time: 0m 12s\n",
            "\tTrain Loss: 0.443 | \t Train Acc:  0.873690\n",
            "\t Val. Loss: 0.370 | \t Valid Acc:  0.890621\n",
            "| Test Loss: 1.160 | \t Test Acc:  0.781187\n",
            "Epoch: 409 | Time: 0m 12s\n",
            "\tTrain Loss: 0.310 | \t Train Acc:  0.908662\n",
            "\t Val. Loss: 0.360 | \t Valid Acc:  0.893568\n",
            "| Test Loss: 1.167 | \t Test Acc:  0.781829\n",
            "Epoch: 410 | Time: 0m 12s\n",
            "\tTrain Loss: 0.306 | \t Train Acc:  0.909874\n",
            "\t Val. Loss: 0.358 | \t Valid Acc:  0.894472\n",
            "| Test Loss: 1.183 | \t Test Acc:  0.782303\n",
            "Epoch: 411 | Time: 0m 12s\n",
            "\tTrain Loss: 0.309 | \t Train Acc:  0.908672\n",
            "\t Val. Loss: 0.362 | \t Valid Acc:  0.892428\n",
            "| Test Loss: 1.231 | \t Test Acc:  0.777872\n",
            "Epoch: 412 | Time: 0m 12s\n",
            "\tTrain Loss: 0.416 | \t Train Acc:  0.882312\n",
            "\t Val. Loss: 0.362 | \t Valid Acc:  0.893283\n",
            "| Test Loss: 1.152 | \t Test Acc:  0.776519\n",
            "Epoch: 413 | Time: 0m 12s\n",
            "\tTrain Loss: 0.313 | \t Train Acc:  0.907501\n",
            "\t Val. Loss: 0.356 | \t Valid Acc:  0.895042\n",
            "| Test Loss: 1.192 | \t Test Acc:  0.779259\n",
            "Epoch: 414 | Time: 0m 12s\n",
            "\tTrain Loss: 0.306 | \t Train Acc:  0.909914\n",
            "\t Val. Loss: 0.356 | \t Valid Acc:  0.894852\n",
            "| Test Loss: 1.191 | \t Test Acc:  0.780544\n",
            "Epoch: 415 | Time: 0m 12s\n",
            "\tTrain Loss: 0.305 | \t Train Acc:  0.909965\n",
            "\t Val. Loss: 0.355 | \t Valid Acc:  0.895042\n",
            "| Test Loss: 1.207 | \t Test Acc:  0.779732\n",
            "Epoch: 416 | Time: 0m 12s\n",
            "\tTrain Loss: 0.303 | \t Train Acc:  0.910904\n",
            "\t Val. Loss: 0.353 | \t Valid Acc:  0.895565\n",
            "| Test Loss: 1.186 | \t Test Acc:  0.781356\n",
            "Epoch: 417 | Time: 0m 12s\n",
            "\tTrain Loss: 0.304 | \t Train Acc:  0.910045\n",
            "\t Val. Loss: 0.354 | \t Valid Acc:  0.895708\n",
            "| Test Loss: 1.192 | \t Test Acc:  0.782100\n",
            "Epoch: 418 | Time: 0m 12s\n",
            "\tTrain Loss: 0.441 | \t Train Acc:  0.878556\n",
            "\t Val. Loss: 0.367 | \t Valid Acc:  0.891857\n",
            "| Test Loss: 1.209 | \t Test Acc:  0.774591\n",
            "Epoch: 419 | Time: 0m 12s\n",
            "\tTrain Loss: 0.383 | \t Train Acc:  0.889975\n",
            "\t Val. Loss: 0.357 | \t Valid Acc:  0.894424\n",
            "| Test Loss: 1.183 | \t Test Acc:  0.779631\n",
            "Epoch: 420 | Time: 0m 12s\n",
            "\tTrain Loss: 0.308 | \t Train Acc:  0.909207\n",
            "\t Val. Loss: 0.359 | \t Valid Acc:  0.893473\n",
            "| Test Loss: 1.187 | \t Test Acc:  0.781863\n",
            "Epoch: 421 | Time: 0m 12s\n",
            "\tTrain Loss: 0.304 | \t Train Acc:  0.910732\n",
            "\t Val. Loss: 0.359 | \t Valid Acc:  0.893664\n",
            "| Test Loss: 1.211 | \t Test Acc:  0.780612\n",
            "Epoch: 422 | Time: 0m 12s\n",
            "\tTrain Loss: 0.302 | \t Train Acc:  0.911075\n",
            "\t Val. Loss: 0.351 | \t Valid Acc:  0.895898\n",
            "| Test Loss: 1.196 | \t Test Acc:  0.782675\n",
            "Epoch: 423 | Time: 0m 12s\n",
            "\tTrain Loss: 0.302 | \t Train Acc:  0.910772\n",
            "\t Val. Loss: 0.355 | \t Valid Acc:  0.894662\n",
            "| Test Loss: 1.210 | \t Test Acc:  0.782979\n",
            "Epoch: 424 | Time: 0m 12s\n",
            "\tTrain Loss: 0.400 | \t Train Acc:  0.885018\n",
            "\t Val. Loss: 0.368 | \t Valid Acc:  0.890954\n",
            "| Test Loss: 1.245 | \t Test Acc:  0.772291\n",
            "Epoch: 425 | Time: 0m 12s\n",
            "\tTrain Loss: 0.326 | \t Train Acc:  0.903877\n",
            "\t Val. Loss: 0.360 | \t Valid Acc:  0.892951\n",
            "| Test Loss: 1.190 | \t Test Acc:  0.779834\n",
            "Epoch: 426 | Time: 0m 12s\n",
            "\tTrain Loss: 0.303 | \t Train Acc:  0.910752\n",
            "\t Val. Loss: 0.352 | \t Valid Acc:  0.896230\n",
            "| Test Loss: 1.177 | \t Test Acc:  0.781525\n",
            "Epoch: 427 | Time: 0m 12s\n",
            "\tTrain Loss: 0.303 | \t Train Acc:  0.910500\n",
            "\t Val. Loss: 0.351 | \t Valid Acc:  0.896040\n",
            "| Test Loss: 1.209 | \t Test Acc:  0.781390\n",
            "Epoch: 428 | Time: 0m 12s\n",
            "\tTrain Loss: 0.301 | \t Train Acc:  0.910974\n",
            "\t Val. Loss: 0.350 | \t Valid Acc:  0.896421\n",
            "| Test Loss: 1.212 | \t Test Acc:  0.782675\n",
            "Epoch: 429 | Time: 0m 12s\n",
            "\tTrain Loss: 0.300 | \t Train Acc:  0.911267\n",
            "\t Val. Loss: 0.348 | \t Valid Acc:  0.896944\n",
            "| Test Loss: 1.234 | \t Test Acc:  0.780815\n",
            "Epoch: 430 | Time: 0m 12s\n",
            "\tTrain Loss: 0.514 | \t Train Acc:  0.867703\n",
            "\t Val. Loss: 0.353 | \t Valid Acc:  0.895993\n",
            "| Test Loss: 1.185 | \t Test Acc:  0.780984\n",
            "Epoch: 431 | Time: 0m 13s\n",
            "\tTrain Loss: 0.317 | \t Train Acc:  0.906381\n",
            "\t Val. Loss: 0.355 | \t Valid Acc:  0.894852\n",
            "| Test Loss: 1.205 | \t Test Acc:  0.781187\n",
            "Epoch: 432 | Time: 0m 12s\n",
            "\tTrain Loss: 0.302 | \t Train Acc:  0.911075\n",
            "\t Val. Loss: 0.358 | \t Valid Acc:  0.893331\n",
            "| Test Loss: 1.197 | \t Test Acc:  0.782607\n",
            "Epoch: 433 | Time: 0m 12s\n",
            "\tTrain Loss: 0.304 | \t Train Acc:  0.910379\n",
            "\t Val. Loss: 0.351 | \t Valid Acc:  0.896326\n",
            "| Test Loss: 1.197 | \t Test Acc:  0.783690\n",
            "Epoch: 434 | Time: 0m 12s\n",
            "\tTrain Loss: 0.345 | \t Train Acc:  0.897597\n",
            "\t Val. Loss: 0.355 | \t Valid Acc:  0.894282\n",
            "| Test Loss: 1.210 | \t Test Acc:  0.780442\n",
            "Epoch: 435 | Time: 0m 12s\n",
            "\tTrain Loss: 0.301 | \t Train Acc:  0.911398\n",
            "\t Val. Loss: 0.353 | \t Valid Acc:  0.895517\n",
            "| Test Loss: 1.194 | \t Test Acc:  0.782675\n",
            "Epoch: 436 | Time: 0m 12s\n",
            "\tTrain Loss: 0.392 | \t Train Acc:  0.889944\n",
            "\t Val. Loss: 0.491 | \t Valid Acc:  0.856871\n",
            "| Test Loss: 1.184 | \t Test Acc:  0.755175\n",
            "Epoch: 437 | Time: 0m 12s\n",
            "\tTrain Loss: 0.324 | \t Train Acc:  0.904170\n",
            "\t Val. Loss: 0.396 | \t Valid Acc:  0.881637\n",
            "| Test Loss: 1.302 | \t Test Acc:  0.766710\n",
            "Epoch: 438 | Time: 0m 12s\n",
            "\tTrain Loss: 0.305 | \t Train Acc:  0.910227\n",
            "\t Val. Loss: 0.354 | \t Valid Acc:  0.894662\n",
            "| Test Loss: 1.213 | \t Test Acc:  0.781322\n",
            "Epoch: 439 | Time: 0m 12s\n",
            "\tTrain Loss: 0.300 | \t Train Acc:  0.911388\n",
            "\t Val. Loss: 0.352 | \t Valid Acc:  0.895612\n",
            "| Test Loss: 1.258 | \t Test Acc:  0.777026\n",
            "Epoch: 440 | Time: 0m 12s\n",
            "\tTrain Loss: 0.301 | \t Train Acc:  0.911005\n",
            "\t Val. Loss: 0.343 | \t Valid Acc:  0.898417\n",
            "| Test Loss: 1.190 | \t Test Acc:  0.784298\n",
            "Epoch: 441 | Time: 0m 12s\n",
            "\tTrain Loss: 0.301 | \t Train Acc:  0.910883\n",
            "\t Val. Loss: 0.344 | \t Valid Acc:  0.897894\n",
            "| Test Loss: 1.237 | \t Test Acc:  0.780984\n",
            "Epoch: 442 | Time: 0m 12s\n",
            "\tTrain Loss: 0.301 | \t Train Acc:  0.910863\n",
            "\t Val. Loss: 0.343 | \t Valid Acc:  0.898037\n",
            "| Test Loss: 1.264 | \t Test Acc:  0.778041\n",
            "Epoch: 443 | Time: 0m 12s\n",
            "\tTrain Loss: 0.434 | \t Train Acc:  0.878496\n",
            "\t Val. Loss: 0.354 | \t Valid Acc:  0.894472\n",
            "| Test Loss: 1.210 | \t Test Acc:  0.777094\n",
            "Epoch: 444 | Time: 0m 12s\n",
            "\tTrain Loss: 0.307 | \t Train Acc:  0.909359\n",
            "\t Val. Loss: 0.343 | \t Valid Acc:  0.899035\n",
            "| Test Loss: 1.201 | \t Test Acc:  0.780815\n",
            "Epoch: 445 | Time: 0m 12s\n",
            "\tTrain Loss: 0.302 | \t Train Acc:  0.911338\n",
            "\t Val. Loss: 0.344 | \t Valid Acc:  0.898512\n",
            "| Test Loss: 1.198 | \t Test Acc:  0.781931\n",
            "Epoch: 446 | Time: 0m 12s\n",
            "\tTrain Loss: 0.299 | \t Train Acc:  0.911843\n",
            "\t Val. Loss: 0.347 | \t Valid Acc:  0.897039\n",
            "| Test Loss: 1.209 | \t Test Acc:  0.782337\n",
            "Epoch: 447 | Time: 0m 12s\n",
            "\tTrain Loss: 0.299 | \t Train Acc:  0.911550\n",
            "\t Val. Loss: 0.343 | \t Valid Acc:  0.898179\n",
            "| Test Loss: 1.217 | \t Test Acc:  0.782201\n",
            "Epoch: 448 | Time: 0m 12s\n",
            "\tTrain Loss: 0.466 | \t Train Acc:  0.874821\n",
            "\t Val. Loss: 0.364 | \t Valid Acc:  0.892475\n",
            "| Test Loss: 1.279 | \t Test Acc:  0.767995\n",
            "Epoch: 449 | Time: 0m 12s\n",
            "\tTrain Loss: 0.365 | \t Train Acc:  0.894690\n",
            "\t Val. Loss: 0.349 | \t Valid Acc:  0.896944\n",
            "| Test Loss: 1.183 | \t Test Acc:  0.782641\n",
            "Epoch: 450 | Time: 0m 12s\n",
            "\tTrain Loss: 0.302 | \t Train Acc:  0.911126\n",
            "\t Val. Loss: 0.346 | \t Valid Acc:  0.897276\n",
            "| Test Loss: 1.204 | \t Test Acc:  0.781626\n",
            "Epoch: 451 | Time: 0m 12s\n",
            "\tTrain Loss: 0.301 | \t Train Acc:  0.911439\n",
            "\t Val. Loss: 0.342 | \t Valid Acc:  0.898987\n",
            "| Test Loss: 1.204 | \t Test Acc:  0.782100\n",
            "Epoch: 452 | Time: 0m 12s\n",
            "\tTrain Loss: 0.300 | \t Train Acc:  0.911388\n",
            "\t Val. Loss: 0.346 | \t Valid Acc:  0.896658\n",
            "| Test Loss: 1.227 | \t Test Acc:  0.782675\n",
            "Epoch: 453 | Time: 0m 12s\n",
            "\tTrain Loss: 0.296 | \t Train Acc:  0.912721\n",
            "\t Val. Loss: 0.347 | \t Valid Acc:  0.896896\n",
            "| Test Loss: 1.258 | \t Test Acc:  0.780916\n",
            "Epoch: 454 | Time: 0m 12s\n",
            "\tTrain Loss: 0.320 | \t Train Acc:  0.905270\n",
            "\t Val. Loss: 1.351 | \t Valid Acc:  0.722441\n",
            "| Test Loss: 2.124 | \t Test Acc:  0.655053\n",
            "Epoch: 455 | Time: 0m 12s\n",
            "\tTrain Loss: 0.379 | \t Train Acc:  0.893791\n",
            "\t Val. Loss: 0.374 | \t Valid Acc:  0.889243\n",
            "| Test Loss: 1.175 | \t Test Acc:  0.774963\n",
            "Epoch: 456 | Time: 0m 12s\n",
            "\tTrain Loss: 0.300 | \t Train Acc:  0.911237\n",
            "\t Val. Loss: 0.343 | \t Valid Acc:  0.898512\n",
            "| Test Loss: 1.192 | \t Test Acc:  0.783554\n",
            "Epoch: 457 | Time: 0m 12s\n",
            "\tTrain Loss: 0.297 | \t Train Acc:  0.912499\n",
            "\t Val. Loss: 0.345 | \t Valid Acc:  0.897561\n",
            "| Test Loss: 1.195 | \t Test Acc:  0.784704\n",
            "Epoch: 458 | Time: 0m 12s\n",
            "\tTrain Loss: 0.296 | \t Train Acc:  0.912579\n",
            "\t Val. Loss: 0.345 | \t Valid Acc:  0.897371\n",
            "| Test Loss: 1.219 | \t Test Acc:  0.783385\n",
            "Epoch: 459 | Time: 0m 12s\n",
            "\tTrain Loss: 0.478 | \t Train Acc:  0.869096\n",
            "\t Val. Loss: 0.358 | \t Valid Acc:  0.894804\n",
            "| Test Loss: 1.169 | \t Test Acc:  0.772460\n",
            "Epoch: 460 | Time: 0m 12s\n",
            "\tTrain Loss: 0.314 | \t Train Acc:  0.907340\n",
            "\t Val. Loss: 0.345 | \t Valid Acc:  0.897561\n",
            "| Test Loss: 1.190 | \t Test Acc:  0.781660\n",
            "Epoch: 461 | Time: 0m 12s\n",
            "\tTrain Loss: 0.301 | \t Train Acc:  0.911257\n",
            "\t Val. Loss: 0.341 | \t Valid Acc:  0.899083\n",
            "| Test Loss: 1.189 | \t Test Acc:  0.782945\n",
            "Epoch: 462 | Time: 0m 12s\n",
            "\tTrain Loss: 0.297 | \t Train Acc:  0.912216\n",
            "\t Val. Loss: 0.338 | \t Valid Acc:  0.899605\n",
            "| Test Loss: 1.203 | \t Test Acc:  0.783351\n",
            "Epoch: 463 | Time: 0m 12s\n",
            "\tTrain Loss: 0.296 | \t Train Acc:  0.912489\n",
            "\t Val. Loss: 0.343 | \t Valid Acc:  0.898322\n",
            "| Test Loss: 1.230 | \t Test Acc:  0.782641\n",
            "Epoch: 464 | Time: 0m 12s\n",
            "\tTrain Loss: 0.298 | \t Train Acc:  0.912014\n",
            "\t Val. Loss: 0.338 | \t Valid Acc:  0.899891\n",
            "| Test Loss: 1.224 | \t Test Acc:  0.781829\n",
            "Epoch: 465 | Time: 0m 12s\n",
            "\tTrain Loss: 0.295 | \t Train Acc:  0.913155\n",
            "\t Val. Loss: 0.336 | \t Valid Acc:  0.900366\n",
            "| Test Loss: 1.238 | \t Test Acc:  0.784062\n",
            "Epoch: 466 | Time: 0m 12s\n",
            "\tTrain Loss: 0.401 | \t Train Acc:  0.889026\n",
            "\t Val. Loss: 0.384 | \t Valid Acc:  0.886914\n",
            "| Test Loss: 1.243 | \t Test Acc:  0.767487\n",
            "Epoch: 467 | Time: 0m 12s\n",
            "\tTrain Loss: 0.308 | \t Train Acc:  0.909177\n",
            "\t Val. Loss: 0.341 | \t Valid Acc:  0.898702\n",
            "| Test Loss: 1.229 | \t Test Acc:  0.780882\n",
            "Epoch: 468 | Time: 0m 12s\n",
            "\tTrain Loss: 0.296 | \t Train Acc:  0.912600\n",
            "\t Val. Loss: 0.345 | \t Valid Acc:  0.897514\n",
            "| Test Loss: 1.232 | \t Test Acc:  0.781795\n",
            "Epoch: 469 | Time: 0m 12s\n",
            "\tTrain Loss: 0.295 | \t Train Acc:  0.913226\n",
            "\t Val. Loss: 0.337 | \t Valid Acc:  0.900176\n",
            "| Test Loss: 1.217 | \t Test Acc:  0.784265\n",
            "Epoch: 470 | Time: 0m 12s\n",
            "\tTrain Loss: 0.297 | \t Train Acc:  0.912105\n",
            "\t Val. Loss: 0.334 | \t Valid Acc:  0.901174\n",
            "| Test Loss: 1.222 | \t Test Acc:  0.784366\n",
            "Epoch: 471 | Time: 0m 12s\n",
            "\tTrain Loss: 0.296 | \t Train Acc:  0.912650\n",
            "\t Val. Loss: 0.342 | \t Valid Acc:  0.898845\n",
            "| Test Loss: 1.256 | \t Test Acc:  0.782269\n",
            "Epoch: 472 | Time: 0m 12s\n",
            "\tTrain Loss: 0.395 | \t Train Acc:  0.888036\n",
            "\t Val. Loss: 0.341 | \t Valid Acc:  0.899891\n",
            "| Test Loss: 1.230 | \t Test Acc:  0.776823\n",
            "Epoch: 473 | Time: 0m 12s\n",
            "\tTrain Loss: 0.318 | \t Train Acc:  0.906633\n",
            "\t Val. Loss: 0.342 | \t Valid Acc:  0.898987\n",
            "| Test Loss: 1.232 | \t Test Acc:  0.780815\n",
            "Epoch: 474 | Time: 0m 12s\n",
            "\tTrain Loss: 0.294 | \t Train Acc:  0.913316\n",
            "\t Val. Loss: 0.345 | \t Valid Acc:  0.897039\n",
            "| Test Loss: 1.240 | \t Test Acc:  0.781965\n",
            "Epoch: 475 | Time: 0m 12s\n",
            "\tTrain Loss: 0.294 | \t Train Acc:  0.913104\n",
            "\t Val. Loss: 0.370 | \t Valid Acc:  0.891334\n",
            "| Test Loss: 1.229 | \t Test Acc:  0.776620\n",
            "Epoch: 476 | Time: 0m 12s\n",
            "\tTrain Loss: 0.296 | \t Train Acc:  0.912337\n",
            "\t Val. Loss: 0.341 | \t Valid Acc:  0.898274\n",
            "| Test Loss: 1.282 | \t Test Acc:  0.778853\n",
            "Epoch: 477 | Time: 0m 12s\n",
            "\tTrain Loss: 0.294 | \t Train Acc:  0.913488\n",
            "\t Val. Loss: 0.345 | \t Valid Acc:  0.897419\n",
            "| Test Loss: 1.260 | \t Test Acc:  0.783791\n",
            "Epoch: 478 | Time: 0m 12s\n",
            "\tTrain Loss: 0.295 | \t Train Acc:  0.912650\n",
            "\t Val. Loss: 0.343 | \t Valid Acc:  0.898274\n",
            "| Test Loss: 1.307 | \t Test Acc:  0.777094\n",
            "Epoch: 479 | Time: 0m 12s\n",
            "\tTrain Loss: 0.390 | \t Train Acc:  0.893488\n",
            "\t Val. Loss: 0.341 | \t Valid Acc:  0.899035\n",
            "| Test Loss: 1.241 | \t Test Acc:  0.780781\n",
            "Epoch: 480 | Time: 0m 12s\n",
            "\tTrain Loss: 0.298 | \t Train Acc:  0.912085\n",
            "\t Val. Loss: 0.337 | \t Valid Acc:  0.900414\n",
            "| Test Loss: 1.226 | \t Test Acc:  0.783893\n",
            "Epoch: 481 | Time: 0m 12s\n",
            "\tTrain Loss: 0.295 | \t Train Acc:  0.912378\n",
            "\t Val. Loss: 0.333 | \t Valid Acc:  0.901554\n",
            "| Test Loss: 1.212 | \t Test Acc:  0.785415\n",
            "Epoch: 482 | Time: 0m 12s\n",
            "\tTrain Loss: 0.438 | \t Train Acc:  0.879697\n",
            "\t Val. Loss: 0.348 | \t Valid Acc:  0.896421\n",
            "| Test Loss: 1.243 | \t Test Acc:  0.776857\n",
            "Epoch: 483 | Time: 0m 12s\n",
            "\tTrain Loss: 0.324 | \t Train Acc:  0.904372\n",
            "\t Val. Loss: 0.337 | \t Valid Acc:  0.900651\n",
            "| Test Loss: 1.230 | \t Test Acc:  0.780950\n",
            "Epoch: 484 | Time: 0m 12s\n",
            "\tTrain Loss: 0.296 | \t Train Acc:  0.912892\n",
            "\t Val. Loss: 0.336 | \t Valid Acc:  0.900984\n",
            "| Test Loss: 1.235 | \t Test Acc:  0.782201\n",
            "Epoch: 485 | Time: 0m 12s\n",
            "\tTrain Loss: 0.293 | \t Train Acc:  0.913629\n",
            "\t Val. Loss: 0.339 | \t Valid Acc:  0.899796\n",
            "| Test Loss: 1.260 | \t Test Acc:  0.781491\n",
            "Epoch: 486 | Time: 0m 12s\n",
            "\tTrain Loss: 0.293 | \t Train Acc:  0.913296\n",
            "\t Val. Loss: 0.332 | \t Valid Acc:  0.902030\n",
            "| Test Loss: 1.223 | \t Test Acc:  0.783791\n",
            "Epoch: 487 | Time: 0m 12s\n",
            "\tTrain Loss: 0.294 | \t Train Acc:  0.913104\n",
            "\t Val. Loss: 0.335 | \t Valid Acc:  0.900746\n",
            "| Test Loss: 1.245 | \t Test Acc:  0.782066\n",
            "Epoch: 488 | Time: 0m 12s\n",
            "\tTrain Loss: 0.294 | \t Train Acc:  0.912862\n",
            "\t Val. Loss: 0.340 | \t Valid Acc:  0.898987\n",
            "| Test Loss: 1.276 | \t Test Acc:  0.780747\n",
            "Epoch: 489 | Time: 0m 12s\n",
            "\tTrain Loss: 0.293 | \t Train Acc:  0.913256\n",
            "\t Val. Loss: 0.348 | \t Valid Acc:  0.896183\n",
            "| Test Loss: 1.351 | \t Test Acc:  0.775504\n",
            "Epoch: 490 | Time: 0m 12s\n",
            "\tTrain Loss: 0.424 | \t Train Acc:  0.882029\n",
            "\t Val. Loss: 0.347 | \t Valid Acc:  0.897229\n",
            "| Test Loss: 1.197 | \t Test Acc:  0.780882\n",
            "Epoch: 491 | Time: 0m 12s\n",
            "\tTrain Loss: 0.305 | \t Train Acc:  0.909773\n",
            "\t Val. Loss: 0.337 | \t Valid Acc:  0.899796\n",
            "| Test Loss: 1.237 | \t Test Acc:  0.783487\n",
            "Epoch: 492 | Time: 0m 12s\n",
            "\tTrain Loss: 0.294 | \t Train Acc:  0.913115\n",
            "\t Val. Loss: 0.334 | \t Valid Acc:  0.901459\n",
            "| Test Loss: 1.237 | \t Test Acc:  0.784332\n",
            "Epoch: 493 | Time: 0m 12s\n",
            "\tTrain Loss: 0.345 | \t Train Acc:  0.899162\n",
            "\t Val. Loss: 0.333 | \t Valid Acc:  0.901935\n",
            "| Test Loss: 1.248 | \t Test Acc:  0.779867\n",
            "Epoch: 494 | Time: 0m 12s\n",
            "\tTrain Loss: 0.295 | \t Train Acc:  0.913286\n",
            "\t Val. Loss: 0.334 | \t Valid Acc:  0.901602\n",
            "| Test Loss: 1.243 | \t Test Acc:  0.783453\n",
            "Epoch: 495 | Time: 0m 12s\n",
            "\tTrain Loss: 0.294 | \t Train Acc:  0.912943\n",
            "\t Val. Loss: 0.333 | \t Valid Acc:  0.901459\n",
            "| Test Loss: 1.242 | \t Test Acc:  0.783893\n",
            "Epoch: 496 | Time: 0m 12s\n",
            "\tTrain Loss: 0.293 | \t Train Acc:  0.913246\n",
            "\t Val. Loss: 0.336 | \t Valid Acc:  0.900366\n",
            "| Test Loss: 1.287 | \t Test Acc:  0.781390\n",
            "Epoch: 497 | Time: 0m 12s\n",
            "\tTrain Loss: 0.292 | \t Train Acc:  0.913367\n",
            "\t Val. Loss: 0.334 | \t Valid Acc:  0.901079\n",
            "| Test Loss: 1.258 | \t Test Acc:  0.784468\n",
            "Epoch: 498 | Time: 0m 12s\n",
            "\tTrain Loss: 0.291 | \t Train Acc:  0.913720\n",
            "\t Val. Loss: 0.339 | \t Valid Acc:  0.899463\n",
            "| Test Loss: 1.301 | \t Test Acc:  0.781187\n",
            "Epoch: 499 | Time: 0m 12s\n",
            "\tTrain Loss: 0.457 | \t Train Acc:  0.876557\n",
            "\t Val. Loss: 0.350 | \t Valid Acc:  0.896421\n",
            "| Test Loss: 1.208 | \t Test Acc:  0.781187\n",
            "Epoch: 500 | Time: 0m 12s\n",
            "\tTrain Loss: 0.296 | \t Train Acc:  0.912569\n",
            "\t Val. Loss: 0.337 | \t Valid Acc:  0.900461\n",
            "| Test Loss: 1.233 | \t Test Acc:  0.781288\n",
            "Epoch: 501 | Time: 0m 12s\n",
            "\tTrain Loss: 0.293 | \t Train Acc:  0.913771\n",
            "\t Val. Loss: 0.330 | \t Valid Acc:  0.902600\n",
            "| Test Loss: 1.245 | \t Test Acc:  0.782303\n",
            "Epoch: 502 | Time: 0m 12s\n",
            "\tTrain Loss: 0.293 | \t Train Acc:  0.913256\n",
            "\t Val. Loss: 0.330 | \t Valid Acc:  0.902410\n",
            "| Test Loss: 1.266 | \t Test Acc:  0.782540\n",
            "Epoch: 503 | Time: 0m 12s\n",
            "\tTrain Loss: 0.291 | \t Train Acc:  0.913953\n",
            "\t Val. Loss: 0.330 | \t Valid Acc:  0.902315\n",
            "| Test Loss: 1.280 | \t Test Acc:  0.781457\n",
            "Epoch: 504 | Time: 0m 12s\n",
            "\tTrain Loss: 0.292 | \t Train Acc:  0.913357\n",
            "\t Val. Loss: 0.329 | \t Valid Acc:  0.902980\n",
            "| Test Loss: 1.260 | \t Test Acc:  0.783013\n",
            "Epoch: 505 | Time: 0m 12s\n",
            "\tTrain Loss: 0.394 | \t Train Acc:  0.888955\n",
            "\t Val. Loss: 0.354 | \t Valid Acc:  0.895517\n",
            "| Test Loss: 1.332 | \t Test Acc:  0.768130\n",
            "Epoch: 506 | Time: 0m 12s\n",
            "\tTrain Loss: 0.332 | \t Train Acc:  0.903372\n",
            "\t Val. Loss: 0.334 | \t Valid Acc:  0.901127\n",
            "| Test Loss: 1.230 | \t Test Acc:  0.783047\n",
            "Epoch: 507 | Time: 0m 12s\n",
            "\tTrain Loss: 0.292 | \t Train Acc:  0.913710\n",
            "\t Val. Loss: 0.332 | \t Valid Acc:  0.901840\n",
            "| Test Loss: 1.255 | \t Test Acc:  0.783250\n",
            "Epoch: 508 | Time: 0m 12s\n",
            "\tTrain Loss: 0.292 | \t Train Acc:  0.913306\n",
            "\t Val. Loss: 0.331 | \t Valid Acc:  0.902172\n",
            "| Test Loss: 1.261 | \t Test Acc:  0.782573\n",
            "Epoch: 509 | Time: 0m 12s\n",
            "\tTrain Loss: 0.291 | \t Train Acc:  0.913912\n",
            "\t Val. Loss: 0.331 | \t Valid Acc:  0.902220\n",
            "| Test Loss: 1.263 | \t Test Acc:  0.783385\n",
            "Epoch: 510 | Time: 0m 12s\n",
            "\tTrain Loss: 0.290 | \t Train Acc:  0.914296\n",
            "\t Val. Loss: 0.335 | \t Valid Acc:  0.901079\n",
            "| Test Loss: 1.253 | \t Test Acc:  0.784197\n",
            "Epoch: 511 | Time: 0m 13s\n",
            "\tTrain Loss: 0.383 | \t Train Acc:  0.894841\n",
            "\t Val. Loss: 0.337 | \t Valid Acc:  0.900128\n",
            "| Test Loss: 1.241 | \t Test Acc:  0.784603\n",
            "Epoch: 512 | Time: 0m 13s\n",
            "\tTrain Loss: 0.293 | \t Train Acc:  0.913327\n",
            "\t Val. Loss: 0.333 | \t Valid Acc:  0.901412\n",
            "| Test Loss: 1.261 | \t Test Acc:  0.782438\n",
            "Epoch: 513 | Time: 0m 13s\n",
            "\tTrain Loss: 0.291 | \t Train Acc:  0.914114\n",
            "\t Val. Loss: 0.332 | \t Valid Acc:  0.902077\n",
            "| Test Loss: 1.254 | \t Test Acc:  0.784671\n",
            "Epoch: 514 | Time: 0m 12s\n",
            "\tTrain Loss: 0.289 | \t Train Acc:  0.914488\n",
            "\t Val. Loss: 0.332 | \t Valid Acc:  0.901745\n",
            "| Test Loss: 1.290 | \t Test Acc:  0.782675\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddCrd9ELwRwB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}